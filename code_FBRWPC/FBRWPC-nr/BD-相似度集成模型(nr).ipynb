{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed4258d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 588.03it/s]\n"
     ]
    }
   ],
   "source": [
    "# %load data_divide - ic.py\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "\n",
    "\n",
    "fold=10\n",
    "\n",
    "dr_pre=np.loadtxt(\"./source_data/nr4_admat_dgc.txt\").T\n",
    "simdr=np.loadtxt(\"./source_data/nr_simmat_drug.txt\")\n",
    "simpre=np.loadtxt(\"./source_data/nr_simmat_target.txt\")\n",
    "\n",
    "\n",
    "prenum=len(simpre)\n",
    "\n",
    "dd_dim1=dr_pre.flatten()\n",
    "\n",
    "i=0\n",
    "list_1=[]\n",
    "while i<len(dd_dim1):\n",
    "    if dd_dim1[i]==1:\n",
    "        list_1.append(i)\n",
    "    i=i+1\n",
    "num1=len(list_1)\n",
    "group_size1=int(num1/fold)\n",
    "random.seed(10)\n",
    "random.shuffle(list_1)\n",
    "#\n",
    "array_1=np.array(list_1)[0:fold*group_size1]\n",
    "group_data1=np.reshape(array_1,(fold,group_size1))\n",
    "np.savetxt(\"./dataset/index_1.txt\",group_data1)\n",
    "\n",
    "\n",
    "i=0\n",
    "list_0=[]\n",
    "while i<len(dd_dim1):\n",
    "    if dd_dim1[i]==0:\n",
    "        list_0.append(i)\n",
    "    i=i+1\n",
    "num0=len(list_0)\n",
    "group_size0=int(num0/fold)\n",
    "random.seed(10)\n",
    "random.shuffle(list_0)\n",
    "\n",
    "array_0=np.array(list_0)[0:fold*group_size0]\n",
    "group_data0=np.reshape(array_0,(fold,group_size0))\n",
    "np.savetxt(\"./dataset/index_0.txt\",group_data0)\n",
    "\n",
    "\n",
    "f = 0\n",
    "for f in trange(fold):\n",
    "    DTI = np.copy(dr_pre)\n",
    "    i=0\n",
    "    while i < group_size1:\n",
    "        r = int(group_data1[f, i] / prenum)\n",
    "        c = int(group_data1[f, i] % prenum)\n",
    "        DTI[r, c] = 0\n",
    "        i += 1  # 得到每次交叉验证中所使用的A矩阵\n",
    "    np.savetxt(\"./dataset/DTI\"+str(f)+\".txt\",DTI)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb794d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load run_main.py\n",
    "import numpy as np\n",
    "from function import *\n",
    "from tqdm import trange\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import sklearn.metrics\n",
    "import copy\n",
    "rs = 0.6\n",
    "n_fold=10\n",
    "eta=0.7\n",
    "l_1=5\n",
    "l_2=5\n",
    "fr=500\n",
    "fp=300\n",
    "K=10\n",
    "#dr_dis=np.loadtxt(\"./source_data/mat_drug_disease.txt\")\n",
    "dr_pre=np.loadtxt(\"./source_data/nr4_admat_dgc.txt\").T\n",
    "#pre_dis=np.loadtxt(\"./source_data/mat_protein_disease.txt\")\n",
    "#dr_dr=np.loadtxt(\"./source_data/mat_drug_drug.txt\")\n",
    "#dr_se=np.loadtxt(\"./source_data/mat_drug_se.txt\")\n",
    "#pre_pre=np.loadtxt(\"./source_data/mat_protein_protein.txt\")\n",
    "simdr=np.loadtxt(\"./source_data/nr_simmat_drug.txt\")\n",
    "simpre=np.loadtxt(\"./source_data/nr_simmat_target.txt\")\n",
    "\n",
    "drnum=len(simdr)\n",
    "#disnum=len(dr_dis[0])\n",
    "prenum=len(simpre)\n",
    "\n",
    "index_1 = np.loadtxt(\"./dataset/index_1.txt\")\n",
    "index_0 = np.loadtxt(\"./dataset/index_0.txt\")\n",
    "index = np.hstack((index_1, index_0))\n",
    "reala=dr_pre\n",
    "sr = simdr\n",
    "sd = simpre\n",
    "\n",
    "RR=np.zeros(dr_pre.shape)\n",
    "#A = np.hstack((dr_dr, dr_dis, dr_se))\n",
    "#B = np.hstack((pre_pre, pre_dis))\n",
    "#cutdr_dis = SVD(A, fr)\n",
    "#cutpre_dis = SVD(B, fp)\n",
    "#pre_simdti = cosine_similarity(cutpre_dis, cutpre_dis)\n",
    "#dr_simdti = cosine_similarity(cutdr_dis, cutdr_dis)\n",
    "pre_simdti = np.loadtxt(\"./source_data/S_FGS_p_nr.txt\")\n",
    "dr_simdti = np.loadtxt(\"./source_data/S_FGS_d_nr.txt\")\n",
    "\n",
    "srfp, spfp = pruning(K=K, drug_mat=dr_simdti, target_mat=pre_simdti, miu=eta)\n",
    "srsp, spsp = pruning(K=K, drug_mat=sr, target_mat=sd, miu=eta)\n",
    "\n",
    "for f in trange(n_fold):\n",
    "    a = np.loadtxt(\"./dataset/DTI\" + str(f) + \".txt\")\n",
    "    idx=index[f,:]\n",
    "   \n",
    "    R = copy.deepcopy(a)\n",
    "    R = BiRW(R, dr_simdti, pre_simdti, a, rs)        \n",
    "    for i in trange(l_1):\n",
    "        R=BiRW(R, srfp, spfp, a, rs/2)\n",
    "    for i in trange(l_2):\n",
    "        R=BiRW(R, srsp, spsp, a, rs/2)\n",
    "\n",
    "    realvalue=np.zeros(R.shape)\n",
    "    for i in range(len(idx)):\n",
    "        d=int(idx[i]/prenum)\n",
    "        p=int(idx[i]%prenum)\n",
    "    \n",
    "        realvalue[d,p]=reala[d,p]\n",
    "    for i in range(len(idx)):\n",
    "        d=int(idx[i]/prenum)\n",
    "        p=int(idx[i]%prenum)\n",
    "        RR[d,p]=R[d,p]\n",
    "\n",
    "y_true_m = dr_pre.tolist()\n",
    "y_pre_m = RR.tolist()\n",
    "\n",
    "tpr_cov=[[] for i in range(n_fold)]\n",
    "fpr_cov=[[] for i in range(n_fold)]\n",
    "recall_cov=[[] for i in range(n_fold)]\n",
    "precision_cov=[[] for i in range(n_fold)]\n",
    "\n",
    "for f in range(n_fold):\n",
    "    print(f)\n",
    "    idx=index[f,:]\n",
    "    singal=[[] for i in range(len(y_true_m))]\n",
    "    singal_test=[[] for i in range(len(y_true_m))]\n",
    "    for i in trange(len(y_true_m)):\n",
    "        for j in range(len(y_true_m[0])):\n",
    "            if i*prenum+j in idx:\n",
    "                singal[i].append(y_true_m[i][j])\n",
    "                singal_test[i].append(y_pre_m[i][j])\n",
    "    y_true=singal\n",
    "    y_pre=singal_test\n",
    "\n",
    "    idx = []\n",
    "    tpr_list = []\n",
    "    fpr_list = []\n",
    "    recall_list = []\n",
    "    precision_list = []\n",
    "    c = 0\n",
    "    for i in trange(len(y_true)):\n",
    "        if np.sum(np.array(y_true[i])) == 0:\n",
    "            c += 1\n",
    "            continue\n",
    "        else:\n",
    "            tpr1, fpr1, precision1, recall1 = tpr_fpr_precision_recall(np.array(y_true[i]), np.array(y_pre[i]))\n",
    "            fpr_list.append(fpr1)\n",
    "            tpr_list.append(tpr1)\n",
    "            precision_list.append(precision1)\n",
    "            recall_list.append(recall1)\n",
    "    coverage = []\n",
    "\n",
    "    for i in tpr_list:\n",
    "        try:\n",
    "            coverage.append(i.index(1.0)+1)\n",
    "        except:\n",
    "            print('1')\n",
    "    print(np.mean(np.array(coverage)))\n",
    "    tpr = equal_len_list(tpr_list)\n",
    "    print(len(tpr ),type(tpr))\n",
    "    fpr = equal_len_list(fpr_list)\n",
    "    precision = equal_len_list(precision_list)\n",
    "    recall = equal_len_list(recall_list)\n",
    "    tpr_mean = np.mean(tpr, axis=0)\n",
    "    tpr_cov[f]=tpr_mean\n",
    "    print(type(tpr_mean),len(tpr_mean))\n",
    "    fpr_mean = np.mean(fpr, axis=0)\n",
    "    fpr_cov[f]=fpr_mean\n",
    "    recall_mean = np.mean(recall, axis=0)\n",
    "    recall_cov[f]=recall_mean\n",
    "    precision_mean = np.mean(precision, axis=0)\n",
    "    precision_cov[f]=precision_mean\n",
    "    print(fpr_mean,tpr_mean)\n",
    "    print('The auc of prediction is:', sklearn.metrics.auc(fpr_mean, tpr_mean))\n",
    "    print('The aupr of prediction is:', sklearn.metrics.auc(recall_mean, precision_mean)+recall_mean[0]*precision_mean[0])\n",
    "    \n",
    "tpr = equal_len_list(tpr_cov)\n",
    "fpr = equal_len_list(fpr_cov)\n",
    "precision = equal_len_list(precision_cov)\n",
    "recall = equal_len_list(recall_cov)\n",
    "\n",
    "tpr_mean = np.mean(tpr, axis=0)\n",
    "fpr_mean = np.mean(fpr, axis=0)\n",
    "recall_mean = np.mean(recall, axis=0)\n",
    "precision_mean = np.mean(precision, axis=0)\n",
    "\n",
    "print('The auc of prediction is:', sklearn.metrics.auc(fpr_mean, tpr_mean))\n",
    "print('The aupr of prediction is:', sklearn.metrics.auc(recall_mean, precision_mean)+recall_mean[0]*precision_mean[0])\n",
    "\n",
    "np.savetxt('./result/fpr_list.txt', fpr_mean)\n",
    "np.savetxt('./result/tpr_list.txt', tpr_mean)\n",
    "np.savetxt('./result/recall_list.txt', recall_mean)\n",
    "np.savetxt('./result/precision_list.txt', precision_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5f9768e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fpr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5167bd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 11991.34it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 27043.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3529411764705883\n",
      "17 <class 'list'>\n",
      "<class 'numpy.ndarray'> 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "f = 1\n",
    "idx=index[f,:]\n",
    "singal=[[] for i in range(len(y_true_m))]\n",
    "singal_test=[[] for i in range(len(y_true_m))]\n",
    "for i in trange(len(y_true_m)):\n",
    "    for j in range(len(y_true_m[0])):\n",
    "        if i*prenum+j in idx:\n",
    "            singal[i].append(y_true_m[i][j])\n",
    "            singal_test[i].append(y_pre_m[i][j])\n",
    "y_true=singal\n",
    "y_pre=singal_test\n",
    "\n",
    "idx = []\n",
    "tpr_list = []\n",
    "fpr_list = []\n",
    "recall_list = []\n",
    "precision_list = []\n",
    "c = 0\n",
    "for i in trange(len(y_true)):\n",
    "    if np.sum(np.array(y_true[i])) == 0:\n",
    "        c += 1\n",
    "        continue\n",
    "    else:\n",
    "        tpr1, fpr1, precision1, recall1 = tpr_fpr_precision_recall(np.array(y_true[i]), np.array(y_pre[i]))\n",
    "        fpr_list.append(fpr1)\n",
    "        tpr_list.append(tpr1)\n",
    "        precision_list.append(precision1)\n",
    "        recall_list.append(recall1)\n",
    "coverage = []\n",
    "\n",
    "for i in tpr_list:\n",
    "    try:\n",
    "        coverage.append(i.index(1.0)+1)\n",
    "    except:\n",
    "        print('1')\n",
    "print(np.mean(np.array(coverage)))\n",
    "\n",
    "tpr = equal_len_list(tpr_list)\n",
    "print(len(tpr ),type(tpr))\n",
    "fpr = equal_len_list(fpr_list)\n",
    "precision = equal_len_list(precision_list)\n",
    "recall = equal_len_list(recall_list)\n",
    "tpr_mean = np.mean(tpr, axis=0)\n",
    "tpr_cov[f]=tpr_mean\n",
    "print(type(tpr_mean),len(tpr_mean))\n",
    "fpr_mean = np.mean(fpr, axis=0)\n",
    "fpr_cov[f]=fpr_mean\n",
    "recall_mean = np.mean(recall, axis=0)\n",
    "recall_cov[f]=recall_mean\n",
    "precision_mean = np.mean(precision, axis=0)\n",
    "precision_cov[f]=precision_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5b82abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The auc of prediction is: 0.7528114186851211\n",
      "The aupr of prediction is: 0.7124134948096885\n"
     ]
    }
   ],
   "source": [
    "print('The auc of prediction is:', sklearn.metrics.auc(fpr_mean, tpr_mean))\n",
    "print('The aupr of prediction is:', sklearn.metrics.auc(recall_mean, precision_mean)+recall_mean[0]*precision_mean[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdccc680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522890b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba3656a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8a63408",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 416.73it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 454.53it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 384.69it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 553.37it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 434.35it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 454.74it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 499.62it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 520.13it/s]\u001b[A\n",
      " 40%|█████████████████████████████████▏                                                 | 4/10 [00:00<00:00, 32.50it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 454.50it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 499.89it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 454.32it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 433.39it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 454.56it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 497.27it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 384.62it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 454.67it/s]\u001b[A\n",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [00:00<00:00, 31.97it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 384.56it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 430.96it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 384.47it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 454.33it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 31.93it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 10786.38it/s]\n",
      "  0%|                                                                                           | 0/54 [00:00<?, ?it/s]D:\\文献阅读\\药物筛选\\BRWCP-main\\BRWCP-FGS-nr\\function.py:50: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  fpr.append(fp / (true.shape[0] - np.sum(true)))\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 26928.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3333333333333333\n",
      "15 <class 'list'>\n",
      "<class 'numpy.ndarray'> 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "At least 2 points are needed to compute area under curve, but x.shape = 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mD:\\Temp\\ipykernel_13804\\2485948162.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[0mprecision_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[0mprecision_cov\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprecision_mean\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'The auc of prediction is:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr_mean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'The aupr of prediction is:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecall_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision_mean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mrecall_mean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mprecision_mean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\PY3\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mauc\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[1;34m\"At least 2 points are needed to compute area under curve, but x.shape = %s\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[1;33m%\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: At least 2 points are needed to compute area under curve, but x.shape = 1"
     ]
    }
   ],
   "source": [
    "tpr = equal_len_list(tpr_cov)\n",
    "fpr = equal_len_list(fpr_cov)\n",
    "precision = equal_len_list(precision_cov)\n",
    "recall = equal_len_list(recall_cov)\n",
    "\n",
    "tpr_mean = np.mean(tpr, axis=0)\n",
    "fpr_mean = np.mean(fpr, axis=0)\n",
    "recall_mean = np.mean(recall, axis=0)\n",
    "precision_mean = np.mean(precision, axis=0)\n",
    "\n",
    "print('The auc of prediction is:', sklearn.metrics.auc(fpr_mean, tpr_mean))\n",
    "print('The aupr of prediction is:', sklearn.metrics.auc(recall_mean, precision_mean)+recall_mean[0]*precision_mean[0])\n",
    "\n",
    "np.savetxt('./result/fpr_list.txt', fpr_mean)\n",
    "np.savetxt('./result/tpr_list.txt', tpr_mean)\n",
    "np.savetxt('./result/recall_list.txt', recall_mean)\n",
    "np.savetxt('./result/precision_list.txt', precision_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef4d348",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=singal\n",
    "y_pre=singal_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cafac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true,y_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8d7e94",
   "metadata": {},
   "outputs": [],
   "source": [
    " fpr_mean = np.mean(fpr, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b46974",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44916322",
   "metadata": {},
   "outputs": [],
   "source": [
    "    tpr = equal_len_list(tpr_list)\n",
    "\n",
    "    print(len(tpr ),type(tpr))\n",
    "    fpr = equal_len_list(fpr_list)\n",
    "    precision = equal_len_list(precision_list)\n",
    "    recall = equal_len_list(recall_list)\n",
    "    tpr_mean = np.mean(tpr, axis=0)\n",
    "    tpr_cov[f]=tpr_mean\n",
    "    print(type(tpr_mean),len(tpr_mean))\n",
    "    fpr_mean = np.mean(fpr, axis=0)\n",
    "    fpr_cov[f]=fpr_mean\n",
    "    recall_mean = np.mean(recall, axis=0)\n",
    "    recall_cov[f]=recall_mean\n",
    "    precision_mean = np.mean(precision, axis=0)\n",
    "    precision_cov[f]=precision_mean\n",
    "    print('The auc of prediction is:', sklearn.metrics.auc(fpr_mean, tpr_mean))\n",
    "    print('The aupr of prediction is:', sklearn.metrics.auc(recall_mean, precision_mean)+recall_mean[0]*precision_mean[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acce63b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tpr ),type(tpr))\n",
    "tpr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25b2dbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr = equal_len_list(fpr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a632f57a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 0.5, 1.0],\n",
       " [0.0, 0.5, 1.0],\n",
       " [0.3333333333333333,\n",
       "  0.6666666666666666,\n",
       "  0.6666666666666666,\n",
       "  0.6666666666666666,\n",
       "  0.6666666666666666,\n",
       "  1.0],\n",
       " [0.0, 0.3333333333333333, 0.6666666666666666, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.2, 0.2, 0.4, 0.6, 0.8, 1.0],\n",
       " [0.0, 0.3333333333333333, 0.6666666666666666, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 1.0],\n",
       " [nan],\n",
       " [0.0, 0.2, 0.4, 0.6, 0.8, 1.0],\n",
       " [0.0, 1.0],\n",
       " [0.0, 0.5, 0.5, 1.0],\n",
       " [0.0, 1.0]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b586edb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr = equal_len_list(fpr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2cedabeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [nan],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "021316af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02650102, 0.15797672, 0.08850578, ..., 0.27766357, 0.074846  ,\n",
       "        0.13572607],\n",
       "       [0.16128143, 0.        , 0.25916219, ..., 0.14127916, 0.07565459,\n",
       "        0.1667835 ],\n",
       "       [0.03231256, 0.27581862, 0.27636061, ..., 0.15315056, 0.0747448 ,\n",
       "        0.14549473],\n",
       "       ...,\n",
       "       [0.13221681, 0.17960728, 0.18401552, ..., 0.07575801, 0.15105219,\n",
       "        0.16021299],\n",
       "       [0.        , 0.27937543, 0.26516794, ..., 0.27291761, 0.10858934,\n",
       "        0.14385806],\n",
       "       [0.05082441, 0.1523691 , 0.27808103, ..., 0.15118054, 0.04921379,\n",
       "        0.1498561 ]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.RR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7343ef52",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_m = dr_pre.tolist()\n",
    "y_pre_m = RR.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c9557b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0],\n",
       " [0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0],\n",
       " [0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0]]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3d5b3a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.026501015042986308,\n",
       "  0.1579767182897703,\n",
       "  0.08850577624331292,\n",
       "  0.04617640426980282,\n",
       "  0.03662538089859609,\n",
       "  0.02682645892510585,\n",
       "  0.14505087456258048,\n",
       "  0.02808850010152287,\n",
       "  0.1420857727303966,\n",
       "  0.14347172437260386,\n",
       "  0.09951286303439713,\n",
       "  0.043712264921415125,\n",
       "  0.06918288351821711,\n",
       "  0.0448181489504202,\n",
       "  0.044673381835837016,\n",
       "  0.041242022414897925,\n",
       "  0.03839265369511714,\n",
       "  0.14353425197917677,\n",
       "  0.25131967399479205,\n",
       "  0.12994129266789983,\n",
       "  0.05259726747828919,\n",
       "  0.052683203885812734,\n",
       "  0.08552213160718049,\n",
       "  0.2776635681494949,\n",
       "  0.07484600118775522,\n",
       "  0.13572606828409697],\n",
       " [0.16128143034183967,\n",
       "  0.0,\n",
       "  0.25916218635840904,\n",
       "  0.15157744732686257,\n",
       "  0.1433246324995238,\n",
       "  0.07106025716625668,\n",
       "  0.2778515829110908,\n",
       "  0.1322566222379124,\n",
       "  0.29567975765034715,\n",
       "  0.1823735894690253,\n",
       "  0.0,\n",
       "  0.07918359100298819,\n",
       "  0.13957860743552386,\n",
       "  0.0,\n",
       "  0.05823784817083179,\n",
       "  0.07426568233876797,\n",
       "  0.1461751464419031,\n",
       "  0.06423442101527972,\n",
       "  0.07603565768399,\n",
       "  0.08403883231765208,\n",
       "  0.14344723673781762,\n",
       "  0.1429774900992851,\n",
       "  0.14136214415958914,\n",
       "  0.14127915644897848,\n",
       "  0.07565459398646023,\n",
       "  0.1667835009617852],\n",
       " [0.03231256151551827,\n",
       "  0.2758186238848961,\n",
       "  0.27636060994727074,\n",
       "  0.13712416422153867,\n",
       "  0.13554952508382387,\n",
       "  0.04254820179272499,\n",
       "  0.15731025949288802,\n",
       "  0.020725227156455018,\n",
       "  0.16278612523271796,\n",
       "  0.0474002760663727,\n",
       "  0.1591361048599146,\n",
       "  0.03737068843169067,\n",
       "  0.13128359037298934,\n",
       "  0.03243703766312039,\n",
       "  0.0211816362149626,\n",
       "  0.0376115614821608,\n",
       "  0.024437851779154564,\n",
       "  0.022972603863042097,\n",
       "  0.1296596544572676,\n",
       "  0.04521360560106588,\n",
       "  0.0310993394387256,\n",
       "  0.030444248871185634,\n",
       "  0.05565751089024397,\n",
       "  0.15315055945672199,\n",
       "  0.07474480379131523,\n",
       "  0.14549473458832202],\n",
       " [0.1499276579931478,\n",
       "  0.1736193917287773,\n",
       "  0.0,\n",
       "  0.0804575262585316,\n",
       "  0.06033663039101254,\n",
       "  0.05081826115489369,\n",
       "  0.2780122029734549,\n",
       "  0.14418460253376308,\n",
       "  0.2079719029896296,\n",
       "  0.264629613208728,\n",
       "  0.21196957696118146,\n",
       "  0.075869476090601,\n",
       "  0.09065288492922212,\n",
       "  0.06276886990470405,\n",
       "  0.07268890697057966,\n",
       "  0.06985674945233492,\n",
       "  0.051923458368311276,\n",
       "  0.054913829669964,\n",
       "  0.13341664905050285,\n",
       "  0.13546780251750762,\n",
       "  0.14733622255417106,\n",
       "  0.05268300338469205,\n",
       "  0.13333674889209013,\n",
       "  0.11759971289784026,\n",
       "  0.07174534537141009,\n",
       "  0.16626810388197694],\n",
       " [0.06939580015088281,\n",
       "  0.1588840934039556,\n",
       "  0.1510175689493085,\n",
       "  0.04249279952969914,\n",
       "  0.028422325120572994,\n",
       "  0.021586575146225445,\n",
       "  0.27990787582399557,\n",
       "  0.027344053019031398,\n",
       "  0.1973172002791721,\n",
       "  0.2748832590131941,\n",
       "  0.19695029473593495,\n",
       "  0.030733165805488023,\n",
       "  0.05028400001071172,\n",
       "  0.0413730310426899,\n",
       "  0.03402214298178802,\n",
       "  0.046863109688793654,\n",
       "  0.04097198967162412,\n",
       "  0.027635839935529746,\n",
       "  0.15545181697311972,\n",
       "  0.05348086110876277,\n",
       "  0.04124704182608219,\n",
       "  0.045657556583536284,\n",
       "  0.055247420150447396,\n",
       "  0.08425524426004018,\n",
       "  0.034499770064005564,\n",
       "  0.04786890291948573],\n",
       " [0.1526832745701269,\n",
       "  0.2161932752229191,\n",
       "  0.1723288070618212,\n",
       "  0.14668520931897533,\n",
       "  0.12501342578842786,\n",
       "  0.10809812466654692,\n",
       "  0.19828128858721922,\n",
       "  0.13996998817826903,\n",
       "  0.1883089614747836,\n",
       "  0.14397121069022967,\n",
       "  0.1764669372586822,\n",
       "  0.10381074756427633,\n",
       "  0.16554926701540149,\n",
       "  0.18546940928158118,\n",
       "  0.18550381508237213,\n",
       "  0.1838461871676212,\n",
       "  0.17440541630658854,\n",
       "  0.17299206644798248,\n",
       "  0.28978801626168016,\n",
       "  0.16742797205574053,\n",
       "  0.12089674043747961,\n",
       "  0.18181890520584396,\n",
       "  0.14782727851970082,\n",
       "  0.19408771141884165,\n",
       "  0.14120059545016825,\n",
       "  0.169892905889452],\n",
       " [0.11010105320429282,\n",
       "  0.26347837326226486,\n",
       "  0.18670578153101444,\n",
       "  0.13421458593193109,\n",
       "  0.11211597097248277,\n",
       "  0.15799244432230825,\n",
       "  0.19352298984046395,\n",
       "  0.10842083083542196,\n",
       "  0.18958670037903333,\n",
       "  0.1545387711868559,\n",
       "  0.26139597397902137,\n",
       "  0.143552037514729,\n",
       "  0.11867531946699347,\n",
       "  0.11159384714143623,\n",
       "  0.10587585282206655,\n",
       "  0.10500556324314154,\n",
       "  0.14514031780438433,\n",
       "  0.08488317252958165,\n",
       "  0.1424152756904883,\n",
       "  0.11036704877321829,\n",
       "  0.0976653545279133,\n",
       "  0.09302872378236879,\n",
       "  0.15820273152045328,\n",
       "  0.13986664453026526,\n",
       "  0.2527975800133915,\n",
       "  0.14619951776948714],\n",
       " [0.038193584048013964,\n",
       "  0.14076342112869727,\n",
       "  0.0902103815851256,\n",
       "  0.04256034423717467,\n",
       "  0.043387256435191215,\n",
       "  0.03869579598906465,\n",
       "  0.14845371542434016,\n",
       "  0.13454280060986307,\n",
       "  0.14563199271032704,\n",
       "  0.0663720801705279,\n",
       "  0.10170183710153376,\n",
       "  0.04274655127765903,\n",
       "  0.07642036178302891,\n",
       "  0.05544947319388603,\n",
       "  0.13367028463011713,\n",
       "  0.04380249511877181,\n",
       "  0.04211530006998625,\n",
       "  0.040924047708838535,\n",
       "  0.1333256102667261,\n",
       "  0.1402908277115352,\n",
       "  0.07173530843913672,\n",
       "  0.04986168544675533,\n",
       "  0.160968330669177,\n",
       "  0.15156984474039836,\n",
       "  0.0614080671775571,\n",
       "  0.15015658969983697],\n",
       " [0.040082096394727124,\n",
       "  0.13617288425966165,\n",
       "  0.14568160844637676,\n",
       "  0.025226126462587872,\n",
       "  0.024907599859076677,\n",
       "  0.012270718899725072,\n",
       "  0.14992502075461472,\n",
       "  0.034173756191898524,\n",
       "  0.14966196228562761,\n",
       "  0.1506535784251701,\n",
       "  0.1678720453659689,\n",
       "  0.1403215017512538,\n",
       "  0.14112514682397376,\n",
       "  0.015875274986593035,\n",
       "  0.02325737966800665,\n",
       "  0.03402525291884268,\n",
       "  0.02531392618087034,\n",
       "  0.01862522255796847,\n",
       "  0.13165047278241382,\n",
       "  0.13220154918429278,\n",
       "  0.03688726492003808,\n",
       "  0.039414925717245274,\n",
       "  0.15281877720185089,\n",
       "  0.0652585712723177,\n",
       "  0.14345651737622994,\n",
       "  0.04166618236403727],\n",
       " [0.032330902764484075,\n",
       "  0.13807522947462897,\n",
       "  0.08672952887756841,\n",
       "  0.04995874744475266,\n",
       "  0.03925758768398106,\n",
       "  0.02637149199720283,\n",
       "  0.11647225730400017,\n",
       "  0.02988740167047303,\n",
       "  0.12646781729254802,\n",
       "  0.0724832573072108,\n",
       "  0.09904479203578379,\n",
       "  0.04413677294942695,\n",
       "  0.0508249953747147,\n",
       "  0.047614979326858146,\n",
       "  0.049584677680860584,\n",
       "  0.046378860748883755,\n",
       "  0.12945174006986276,\n",
       "  0.03619984977755432,\n",
       "  0.051124618955586995,\n",
       "  0.06630431217434496,\n",
       "  0.04110385331014067,\n",
       "  0.04678631699424546,\n",
       "  0.2621638357165516,\n",
       "  0.18740675965762618,\n",
       "  0.17341387910493686,\n",
       "  0.1392356127429144],\n",
       " [0.16740390455378362,\n",
       "  0.19012564569625998,\n",
       "  0.1566324386891929,\n",
       "  0.04685751275156354,\n",
       "  0.03494954261344039,\n",
       "  0.022776913788518295,\n",
       "  0.19440887946450236,\n",
       "  0.02292893254192481,\n",
       "  0.2958509782278005,\n",
       "  0.2535582884835069,\n",
       "  0.2932563860185024,\n",
       "  0.03181872362683737,\n",
       "  0.047407794107122425,\n",
       "  0.024155785983401096,\n",
       "  0.022953550666606256,\n",
       "  0.035746385139480016,\n",
       "  0.04168078009405781,\n",
       "  0.025288515002297996,\n",
       "  0.1553479555273649,\n",
       "  0.1279466019378903,\n",
       "  0.03724000956303074,\n",
       "  0.03622031855187566,\n",
       "  0.05810367924748283,\n",
       "  0.07179039277563906,\n",
       "  0.02950404457339592,\n",
       "  0.050579721350372614],\n",
       " [0.020093665747041144,\n",
       "  0.13569404627489362,\n",
       "  0.0631312930638019,\n",
       "  0.03150750799799943,\n",
       "  0.024403590128045518,\n",
       "  0.018847314906372058,\n",
       "  0.09980218378542903,\n",
       "  0.036609571177870795,\n",
       "  0.08635512272548078,\n",
       "  0.048129576146697495,\n",
       "  0.07982283029571996,\n",
       "  0.03193167538065625,\n",
       "  0.055106746304591225,\n",
       "  0.029525602751246903,\n",
       "  0.036397084103356445,\n",
       "  0.13536609013231582,\n",
       "  0.030625919278684334,\n",
       "  0.019263476907236763,\n",
       "  0.12646474663695714,\n",
       "  0.05275922423821432,\n",
       "  0.0331891606519747,\n",
       "  0.1374237444084439,\n",
       "  0.0,\n",
       "  0.15132766397005598,\n",
       "  0.06081072067830626,\n",
       "  0.14400488892332922],\n",
       " [0.024964877773811515,\n",
       "  0.14322429894566044,\n",
       "  0.14197542416382547,\n",
       "  0.06175077867427444,\n",
       "  0.028551078969800074,\n",
       "  0.04311760706369519,\n",
       "  0.12061346947103904,\n",
       "  0.03002852107530121,\n",
       "  0.11954654910311574,\n",
       "  0.07861786619253819,\n",
       "  0.13857293787430133,\n",
       "  0.05810842282491881,\n",
       "  0.08366341716225584,\n",
       "  0.03800243502802331,\n",
       "  0.0608424060780509,\n",
       "  0.13432440323047845,\n",
       "  0.13237247115738054,\n",
       "  0.021827528185344027,\n",
       "  0.05045414771732323,\n",
       "  0.07176721708744216,\n",
       "  0.057039508281716195,\n",
       "  0.1370352009317019,\n",
       "  0.16370590041080174,\n",
       "  0.17298681957521947,\n",
       "  0.1432536801744057,\n",
       "  0.14528141344846934],\n",
       " [0.019003894133631724,\n",
       "  0.11439236618353844,\n",
       "  0.06138240913141743,\n",
       "  0.03331173780420691,\n",
       "  0.024679249548379675,\n",
       "  0.017894220423085572,\n",
       "  0.140103934789182,\n",
       "  0.01263952863303082,\n",
       "  0.084996856437321,\n",
       "  0.05690126207668013,\n",
       "  0.06936423304678989,\n",
       "  0.029352299910334084,\n",
       "  0.04243110464820469,\n",
       "  0.022681336216695554,\n",
       "  0.023468366842109435,\n",
       "  0.029405444450891355,\n",
       "  0.019672771225874998,\n",
       "  0.01844958480777808,\n",
       "  0.04635499207865687,\n",
       "  0.04475828789302105,\n",
       "  0.027590569617291456,\n",
       "  0.03420519974663661,\n",
       "  0.1368641292910227,\n",
       "  0.15432069633686862,\n",
       "  0.14986081627749814,\n",
       "  0.1607418395422848],\n",
       " [0.1375518198548233,\n",
       "  0.13562514495909006,\n",
       "  0.0723592418311537,\n",
       "  0.04002795159139719,\n",
       "  0.03130487201120454,\n",
       "  0.025973886102101183,\n",
       "  0.2963718198726778,\n",
       "  0.01118589884242303,\n",
       "  0.290586793747038,\n",
       "  0.17310792856981233,\n",
       "  0.15660490187596549,\n",
       "  0.024377492860417578,\n",
       "  0.04786331642558564,\n",
       "  0.03266395375343689,\n",
       "  0.03058946544478778,\n",
       "  0.03709848377507603,\n",
       "  0.03217943315568915,\n",
       "  0.020290762865428906,\n",
       "  0.052103032929476684,\n",
       "  0.05131405899917228,\n",
       "  0.03219225094207339,\n",
       "  0.03665282813595555,\n",
       "  0.05787399079877155,\n",
       "  0.08739537608618966,\n",
       "  0.025586003689238482,\n",
       "  0.02632041942899399],\n",
       " [0.027490392108615175,\n",
       "  0.1351125720791499,\n",
       "  0.08234838676762404,\n",
       "  0.03257256678082567,\n",
       "  0.040514186160707656,\n",
       "  0.027127545981007542,\n",
       "  0.11856431018957857,\n",
       "  0.023898073184004533,\n",
       "  0.11198903004377639,\n",
       "  0.0665073121023631,\n",
       "  0.09485722304239008,\n",
       "  0.1429584493844804,\n",
       "  0.14332862680544295,\n",
       "  0.04235808772564409,\n",
       "  0.037236859943405365,\n",
       "  0.04836812106622518,\n",
       "  0.04095431642461047,\n",
       "  0.02902792188389038,\n",
       "  0.06853134790860102,\n",
       "  0.05292296151545671,\n",
       "  0.0329637231374027,\n",
       "  0.02245967976504361,\n",
       "  0.07149645706232048,\n",
       "  0.15641847941314144,\n",
       "  0.055177961776610794,\n",
       "  0.044971635092667224],\n",
       " [0.020654737414738014,\n",
       "  0.1694332864378514,\n",
       "  0.14054521135955983,\n",
       "  0.025896365302768093,\n",
       "  0.025212778622537037,\n",
       "  0.0196107173442249,\n",
       "  0.09263537430751616,\n",
       "  0.015635741504488987,\n",
       "  0.16015208642763323,\n",
       "  0.05647530341584827,\n",
       "  0.07652527797277835,\n",
       "  0.0336016699993187,\n",
       "  0.050206457042482805,\n",
       "  0.031914576883098296,\n",
       "  0.028568383560133512,\n",
       "  0.03345171095620879,\n",
       "  0.024847122333724807,\n",
       "  0.021134937201142616,\n",
       "  0.04067191742250605,\n",
       "  0.05373273011760273,\n",
       "  0.029747720836355247,\n",
       "  0.034442771914832,\n",
       "  0.15978715245970637,\n",
       "  0.07261393645172823,\n",
       "  0.021961344395271025,\n",
       "  0.04706188126989574],\n",
       " [0.02585545201817885,\n",
       "  0.18887812900508705,\n",
       "  0.27712720363305865,\n",
       "  0.045908464656812864,\n",
       "  0.044413576057421265,\n",
       "  0.02830560129943794,\n",
       "  0.11964458978339046,\n",
       "  0.028762517042039925,\n",
       "  0.10376720827294368,\n",
       "  0.05578496008046095,\n",
       "  0.1526496778333413,\n",
       "  0.04182024810597977,\n",
       "  0.05656340037903277,\n",
       "  0.03642872338637632,\n",
       "  0.032907320828447335,\n",
       "  0.037460777740948026,\n",
       "  0.03721281545660435,\n",
       "  0.030548709202481362,\n",
       "  0.06441454870127165,\n",
       "  0.049120623922010886,\n",
       "  0.03288603755812796,\n",
       "  0.042792084959183935,\n",
       "  0.057869877602461595,\n",
       "  0.06971253033482944,\n",
       "  0.037581416102362056,\n",
       "  0.1436846747908975],\n",
       " [0.25132514190130145,\n",
       "  0.1645398842113346,\n",
       "  0.12563112145172883,\n",
       "  0.06820551724113123,\n",
       "  0.07584477201190887,\n",
       "  0.071502397950326,\n",
       "  0.143491580664915,\n",
       "  0.16826412767320617,\n",
       "  0.1349926095539164,\n",
       "  0.09149906214802186,\n",
       "  0.12355740738957377,\n",
       "  0.071735128250061,\n",
       "  0.08441534424851521,\n",
       "  0.29456659804388896,\n",
       "  0.2944780771137039,\n",
       "  0.2945729316311123,\n",
       "  0.16930395549744967,\n",
       "  0.15151146600197282,\n",
       "  0.08399787020946776,\n",
       "  0.273838978614008,\n",
       "  0.2739998901931084,\n",
       "  0.2742325688007641,\n",
       "  0.25426463593347837,\n",
       "  0.12948711502169424,\n",
       "  0.07903540513607983,\n",
       "  0.08898495544668682],\n",
       " [0.05576975428375737,\n",
       "  0.15998288715776116,\n",
       "  0.1651121058071019,\n",
       "  0.043648517585376134,\n",
       "  0.0297519693333124,\n",
       "  0.030331293397530854,\n",
       "  0.17968355472530595,\n",
       "  0.02706225546135081,\n",
       "  0.1937040167216668,\n",
       "  0.28158554007912573,\n",
       "  0.1822353240604483,\n",
       "  0.03415672768748432,\n",
       "  0.05214384690396019,\n",
       "  0.038699820218609765,\n",
       "  0.03736401657080256,\n",
       "  0.031811086638548515,\n",
       "  0.04004212973166016,\n",
       "  0.02608896660385528,\n",
       "  0.1562459500857505,\n",
       "  0.1534143518114477,\n",
       "  0.03946095123727618,\n",
       "  0.03962074500710651,\n",
       "  0.04309580773476722,\n",
       "  0.06952882112710815,\n",
       "  0.03249208133371519,\n",
       "  0.14352044516207596],\n",
       " [0.161177863533332,\n",
       "  0.15864071740246974,\n",
       "  0.09906994747937965,\n",
       "  0.053047582376475624,\n",
       "  0.052501617955305016,\n",
       "  0.0435555952460287,\n",
       "  0.16218450915517482,\n",
       "  0.05076757577258549,\n",
       "  0.11696080649958579,\n",
       "  0.08869018786062088,\n",
       "  0.11268285936703182,\n",
       "  0.06854739786538919,\n",
       "  0.07371891306418735,\n",
       "  0.29605667571390804,\n",
       "  0.2960758851802492,\n",
       "  0.2960169125592812,\n",
       "  0.1650802601583594,\n",
       "  0.16393640719450553,\n",
       "  0.15902582756959557,\n",
       "  0.17229122591792392,\n",
       "  0.17362892951646453,\n",
       "  0.17701880268567896,\n",
       "  0.16421807729190455,\n",
       "  0.15302118473709828,\n",
       "  0.1435320039051698,\n",
       "  0.17109063193118687],\n",
       " [0.16795077328212182,\n",
       "  0.18005284489033851,\n",
       "  0.10459538762102163,\n",
       "  0.06683129285131971,\n",
       "  0.05986750247920711,\n",
       "  0.05189366556849309,\n",
       "  0.2959662981800668,\n",
       "  0.05309402340863634,\n",
       "  0.2904902235825527,\n",
       "  0.295104783958987,\n",
       "  0.1985856154103378,\n",
       "  0.14422314974422723,\n",
       "  0.06836102748427297,\n",
       "  0.05794099673065106,\n",
       "  0.055319191658173714,\n",
       "  0.06557840768193761,\n",
       "  0.06667244885402347,\n",
       "  0.05381632042909436,\n",
       "  0.08313992858568639,\n",
       "  0.0720651602715237,\n",
       "  0.056572302398393275,\n",
       "  0.05751755524966308,\n",
       "  0.14090958392608832,\n",
       "  0.10215036869243549,\n",
       "  0.13560881911244235,\n",
       "  0.05373792330324884],\n",
       " [0.04363791398144098,\n",
       "  0.15847016891932025,\n",
       "  0.06219201693363173,\n",
       "  0.024321804313634947,\n",
       "  0.02395159752554646,\n",
       "  0.017539917511575732,\n",
       "  0.15029346826961382,\n",
       "  0.025126719442287268,\n",
       "  0.1610795387409284,\n",
       "  0.1507003885873023,\n",
       "  0.07147096538240817,\n",
       "  0.027877274422044348,\n",
       "  0.03805084134623199,\n",
       "  0.027939695124315423,\n",
       "  0.020416522780330463,\n",
       "  0.032666869609125765,\n",
       "  0.03940073554262852,\n",
       "  0.01848611671674897,\n",
       "  0.15488330471585862,\n",
       "  0.133744008588124,\n",
       "  0.03543023483346579,\n",
       "  0.026083152612019773,\n",
       "  0.051426795015057404,\n",
       "  0.13593295264856717,\n",
       "  0.020977885358867323,\n",
       "  0.04720386341400793],\n",
       " [0.0267047232540394,\n",
       "  0.15756915506448815,\n",
       "  0.08683350463139941,\n",
       "  0.03859354134644584,\n",
       "  0.0391756982148902,\n",
       "  0.03526198758441104,\n",
       "  0.10274546791976723,\n",
       "  0.026908667156076413,\n",
       "  0.15880017117736803,\n",
       "  0.051085570652499177,\n",
       "  0.0817062891050552,\n",
       "  0.037460998758473626,\n",
       "  0.059605421484390894,\n",
       "  0.03931521588303426,\n",
       "  0.03930483873144214,\n",
       "  0.04433100164920305,\n",
       "  0.03904184428350956,\n",
       "  0.023776787195064493,\n",
       "  0.13010312649809994,\n",
       "  0.05344344040991901,\n",
       "  0.02743219455934808,\n",
       "  0.0309921990498034,\n",
       "  0.1567335886256312,\n",
       "  0.2730404451216008,\n",
       "  0.14711886458599535,\n",
       "  0.06344904189548715],\n",
       " [0.04075859518955412,\n",
       "  0.1359703597578158,\n",
       "  0.2805728474845123,\n",
       "  0.03678176815835273,\n",
       "  0.1374421467757342,\n",
       "  0.04621863202052743,\n",
       "  0.14364389874188355,\n",
       "  0.042327713629803906,\n",
       "  0.17558329445759552,\n",
       "  0.15246548065440688,\n",
       "  0.18485497632671288,\n",
       "  0.051301175251002404,\n",
       "  0.13521201263114524,\n",
       "  0.03237013294020551,\n",
       "  0.050117082235617935,\n",
       "  0.05603877874198572,\n",
       "  0.04996000808033252,\n",
       "  0.03974856726755446,\n",
       "  0.13835657896312079,\n",
       "  0.06655916683141051,\n",
       "  0.047411498829856624,\n",
       "  0.05191287689459346,\n",
       "  0.1682544914805246,\n",
       "  0.25165622724589787,\n",
       "  0.1397309040435425,\n",
       "  0.14261285144514046],\n",
       " [0.03366420424829804,\n",
       "  0.12753718460717117,\n",
       "  0.0772491568383889,\n",
       "  0.05631196748684453,\n",
       "  0.05364077710580615,\n",
       "  0.045471590383893035,\n",
       "  0.12248921419241193,\n",
       "  0.03523380242951907,\n",
       "  0.12079375846678353,\n",
       "  0.057970480079734855,\n",
       "  0.09460889161086801,\n",
       "  0.26311733595795705,\n",
       "  0.2639857827401827,\n",
       "  0.04294835644629998,\n",
       "  0.033894894428484645,\n",
       "  0.03967862190827013,\n",
       "  0.04731733220649707,\n",
       "  0.028472900020525747,\n",
       "  0.07067231323238574,\n",
       "  0.05931315742752752,\n",
       "  0.04152516117937287,\n",
       "  0.04311733047005422,\n",
       "  0.14097862069142164,\n",
       "  0.1660424329892905,\n",
       "  0.2512901986440319,\n",
       "  0.056718363958057426],\n",
       " [0.11072038905681889,\n",
       "  0.28445720859999946,\n",
       "  0.2835405126806946,\n",
       "  0.136206052517877,\n",
       "  0.1398960173036871,\n",
       "  0.15664473417520122,\n",
       "  0.17675947334508568,\n",
       "  0.11143265692945564,\n",
       "  0.17727755370434845,\n",
       "  0.1410768253360702,\n",
       "  0.16938283160387452,\n",
       "  0.11832171425527067,\n",
       "  0.13038337285698023,\n",
       "  0.11391918645172545,\n",
       "  0.1127700623046151,\n",
       "  0.11524340012672211,\n",
       "  0.09286501848922987,\n",
       "  0.07390757944976842,\n",
       "  0.14406691243335307,\n",
       "  0.11135588116841989,\n",
       "  0.10677264917440663,\n",
       "  0.08404026756339508,\n",
       "  0.15425247633773462,\n",
       "  0.1867006384914043,\n",
       "  0.10522419630447502,\n",
       "  0.14136105478758454],\n",
       " [0.16969522302683127,\n",
       "  0.2955153493300321,\n",
       "  0.18472456980603327,\n",
       "  0.061878270241103886,\n",
       "  0.05386927960634184,\n",
       "  0.05502707511753469,\n",
       "  0.29932080367756003,\n",
       "  0.04270589334436113,\n",
       "  0.0,\n",
       "  0.19409666401797243,\n",
       "  0.2763377654187076,\n",
       "  0.05150686808795047,\n",
       "  0.07204552549548057,\n",
       "  0.0616631717534447,\n",
       "  0.05416934129290824,\n",
       "  0.06174651440624164,\n",
       "  0.05218361207622959,\n",
       "  0.04711747799980813,\n",
       "  0.0913706394933146,\n",
       "  0.07041344902024149,\n",
       "  0.054975836911961444,\n",
       "  0.0514490136592173,\n",
       "  0.13977769716666338,\n",
       "  0.09263291003606736,\n",
       "  0.13340027867656484,\n",
       "  0.14523059945406339],\n",
       " [0.047180763924376395,\n",
       "  0.1433296499368664,\n",
       "  0.14092711994146792,\n",
       "  0.0627399033052889,\n",
       "  0.043952176352167874,\n",
       "  0.05758946047784689,\n",
       "  0.12584174121203412,\n",
       "  0.045722901663993426,\n",
       "  0.16770201679040164,\n",
       "  0.0877107047738821,\n",
       "  0.13985230895681147,\n",
       "  0.037456638486871655,\n",
       "  0.0744128514557818,\n",
       "  0.06245447703746729,\n",
       "  0.06086750292744175,\n",
       "  0.06650078247255001,\n",
       "  0.1325157114641844,\n",
       "  0.056556917799491395,\n",
       "  0.05657118021172841,\n",
       "  0.06677338495755492,\n",
       "  0.06137287641536364,\n",
       "  0.05786549551047846,\n",
       "  0.14156072619343452,\n",
       "  0.17358094910088429,\n",
       "  0.2578149230383979,\n",
       "  0.15456721822625624],\n",
       " [0.13694268962080808,\n",
       "  0.15440621432614154,\n",
       "  0.152009735304889,\n",
       "  0.060833258971651705,\n",
       "  0.06738324163324691,\n",
       "  0.06519378327219748,\n",
       "  0.12971465348658986,\n",
       "  0.15287936140519315,\n",
       "  0.13858752517079068,\n",
       "  0.09148791071758884,\n",
       "  0.1127021741128518,\n",
       "  0.15339348895826196,\n",
       "  0.0,\n",
       "  0.07126305702331162,\n",
       "  0.057521304651224195,\n",
       "  0.07787894848217751,\n",
       "  0.05775248168184573,\n",
       "  0.05520339505251045,\n",
       "  0.06767962384092586,\n",
       "  0.17550351260099856,\n",
       "  0.1547793770202469,\n",
       "  0.1547912724655881,\n",
       "  0.16140341444514966,\n",
       "  0.10576954895162086,\n",
       "  0.05379846241942631,\n",
       "  0.07065184551651735],\n",
       " [0.0395685102568927,\n",
       "  0.10241864426951347,\n",
       "  0.06016902325023042,\n",
       "  0.031955990974024864,\n",
       "  0.02896885140220791,\n",
       "  0.02773061586736219,\n",
       "  0.08538921799029295,\n",
       "  0.040941007180403444,\n",
       "  0.07521655993656835,\n",
       "  0.041159439202027075,\n",
       "  0.07880192528728194,\n",
       "  0.27287652337726287,\n",
       "  0.16698486770962348,\n",
       "  0.02395849794228038,\n",
       "  0.02448473201993845,\n",
       "  0.025735042692317606,\n",
       "  0.13284423355634323,\n",
       "  0.05266861700930264,\n",
       "  0.05082306934878031,\n",
       "  0.14509158710860728,\n",
       "  0.14456189095412697,\n",
       "  0.03999979543870203,\n",
       "  0.06311362260430776,\n",
       "  0.07441672847577685,\n",
       "  0.024952487932962543,\n",
       "  0.03199224421557924],\n",
       " [0.018646018722558173,\n",
       "  0.1293894139721556,\n",
       "  0.0685515272860728,\n",
       "  0.028834115909374416,\n",
       "  0.02095072032440096,\n",
       "  0.01646938015824708,\n",
       "  0.0,\n",
       "  0.012631554118836538,\n",
       "  0.15747514233705515,\n",
       "  0.1868132515127931,\n",
       "  0.16302860318170886,\n",
       "  0.031005904205371325,\n",
       "  0.0424344855788965,\n",
       "  0.030108793051243796,\n",
       "  0.029531123683451448,\n",
       "  0.029906425902510726,\n",
       "  0.026710956751703468,\n",
       "  0.01898985702455274,\n",
       "  0.051582545370403216,\n",
       "  0.036109217795638464,\n",
       "  0.02512461584552817,\n",
       "  0.02728644281813314,\n",
       "  0.05339823080850608,\n",
       "  0.06864880489076375,\n",
       "  0.019468826703220816,\n",
       "  0.03095729300137643],\n",
       " [0.019624120833028467,\n",
       "  0.12342170130607627,\n",
       "  0.06889270603857606,\n",
       "  0.02533103425831089,\n",
       "  0.028008082967169008,\n",
       "  0.02722179651382243,\n",
       "  0.15585920177271625,\n",
       "  0.010749333842725237,\n",
       "  0.10654269019523778,\n",
       "  0.06438553425137311,\n",
       "  0.0755768859579275,\n",
       "  0.15196143582767532,\n",
       "  0.15240328493818406,\n",
       "  0.028602577188623395,\n",
       "  0.028796320471634697,\n",
       "  0.028792944563900122,\n",
       "  0.025579459470480757,\n",
       "  0.018932650157793277,\n",
       "  0.05411887337139385,\n",
       "  0.039676244815044066,\n",
       "  0.016371888485718043,\n",
       "  0.03354435603010808,\n",
       "  0.1425742848784652,\n",
       "  0.06192301012125474,\n",
       "  0.13986019890782925,\n",
       "  0.042607730624535156],\n",
       " [0.032076274340126214,\n",
       "  0.2672347964227636,\n",
       "  0.26738467475441297,\n",
       "  0.14480251818924936,\n",
       "  0.1572554782201902,\n",
       "  0.15715052695164136,\n",
       "  0.1449924045604589,\n",
       "  0.023031141851582206,\n",
       "  0.08424111122891301,\n",
       "  0.0594763862034684,\n",
       "  0.16206487749210308,\n",
       "  0.03908477496144488,\n",
       "  0.04651677710933642,\n",
       "  0.028997534555082354,\n",
       "  0.029217650739338276,\n",
       "  0.03964103752792046,\n",
       "  0.030893058612245235,\n",
       "  0.024084268386694176,\n",
       "  0.05439534311169371,\n",
       "  0.04993261811037461,\n",
       "  0.033955501646750964,\n",
       "  0.032984533211343356,\n",
       "  0.049578222356865584,\n",
       "  0.15718847560711738,\n",
       "  0.049242700885277824,\n",
       "  0.14247927685157905],\n",
       " [0.02531233821965177,\n",
       "  0.1589781053367463,\n",
       "  0.058268038860400544,\n",
       "  0.030870487746124296,\n",
       "  0.024388020514689336,\n",
       "  0.013588334409214139,\n",
       "  0.08714682929701191,\n",
       "  0.01520586161472428,\n",
       "  0.17203599599961433,\n",
       "  0.04350450972860501,\n",
       "  0.1650331547406013,\n",
       "  0.026820002297408274,\n",
       "  0.04871808396709576,\n",
       "  0.030491590838966326,\n",
       "  0.027111118661679277,\n",
       "  0.032031608962777076,\n",
       "  0.03510745366556797,\n",
       "  0.020069943116794033,\n",
       "  0.04015859249107753,\n",
       "  0.05185249906581102,\n",
       "  0.0340059551882411,\n",
       "  0.033743099398436276,\n",
       "  0.1592873990270088,\n",
       "  0.14852141703815708,\n",
       "  0.0489980217450377,\n",
       "  0.14160851154579254],\n",
       " [0.15985550514064464,\n",
       "  0.190900362277399,\n",
       "  0.15963146219154728,\n",
       "  0.14993873441248415,\n",
       "  0.1367793532963543,\n",
       "  0.04384979088786891,\n",
       "  0.1587761079631062,\n",
       "  0.028961320786632157,\n",
       "  0.27426331319517416,\n",
       "  0.17792944744125716,\n",
       "  0.19577431722110286,\n",
       "  0.03602691616361059,\n",
       "  0.1321643416477343,\n",
       "  0.03980309544134778,\n",
       "  0.03769484369556869,\n",
       "  0.040400565811530675,\n",
       "  0.04156238282841038,\n",
       "  0.03126025298073119,\n",
       "  0.15576397721748717,\n",
       "  0.0567558800104414,\n",
       "  0.04271744070809122,\n",
       "  0.04078052747978683,\n",
       "  0.057908602866505204,\n",
       "  0.1361701647390359,\n",
       "  0.04131333051044335,\n",
       "  0.14405589686908138],\n",
       " [0.16210210536005745,\n",
       "  0.1926125469628187,\n",
       "  0.2744688885604345,\n",
       "  0.15390656227026836,\n",
       "  0.1405507892300667,\n",
       "  0.04454275194346621,\n",
       "  0.18421048041632013,\n",
       "  0.048125754088704245,\n",
       "  0.2752463525990393,\n",
       "  0.1759558447921296,\n",
       "  0.18884900141786093,\n",
       "  0.058684569551829456,\n",
       "  0.14021113275032226,\n",
       "  0.05208112557560789,\n",
       "  0.053744984320709704,\n",
       "  0.06047834156396352,\n",
       "  0.1455541287435102,\n",
       "  0.05542204510525117,\n",
       "  0.1532885248372655,\n",
       "  0.13536146206282518,\n",
       "  0.04495086397021468,\n",
       "  0.05225069984943287,\n",
       "  0.07571010186490532,\n",
       "  0.14193880321781946,\n",
       "  0.0585124565680211,\n",
       "  0.14472160241038973],\n",
       " [0.1665813140117138,\n",
       "  0.17558284018424242,\n",
       "  0.1650003336155763,\n",
       "  0.05183494029678251,\n",
       "  0.04387108877302953,\n",
       "  0.03662013350639678,\n",
       "  0.16399369062450636,\n",
       "  0.032445797055158265,\n",
       "  0.2932827822361602,\n",
       "  0.17787889146036454,\n",
       "  0.25401923307336455,\n",
       "  0.04591297385420347,\n",
       "  0.06138784539401815,\n",
       "  0.028774024615901575,\n",
       "  0.036335715564584446,\n",
       "  0.0442260604847934,\n",
       "  0.04298837263507284,\n",
       "  0.03290099560113072,\n",
       "  0.13327586193774157,\n",
       "  0.047051337211972674,\n",
       "  0.04537702513378402,\n",
       "  0.037594342847676814,\n",
       "  0.06481663493468802,\n",
       "  0.08569896568458735,\n",
       "  0.033474849614805055,\n",
       "  0.14299097143270498],\n",
       " [0.07619037630116382,\n",
       "  0.16233657644334057,\n",
       "  0.17240176232862903,\n",
       "  0.03775223596631562,\n",
       "  0.03323842693330124,\n",
       "  0.026097028802190517,\n",
       "  0.17843677812454772,\n",
       "  0.036135475674671576,\n",
       "  0.17305523597276395,\n",
       "  0.16293134293404968,\n",
       "  0.15492669064853262,\n",
       "  0.023115237169978986,\n",
       "  0.04551770962413031,\n",
       "  0.035775186663467635,\n",
       "  0.034244604285480894,\n",
       "  0.04058768850402529,\n",
       "  0.03554204018078591,\n",
       "  0.024989129103418016,\n",
       "  0.13341691947328838,\n",
       "  0.13431474010311464,\n",
       "  0.036882628517578564,\n",
       "  0.036295562564263216,\n",
       "  0.05575703946698278,\n",
       "  0.07176047535128476,\n",
       "  0.030512014328713217,\n",
       "  0.14278948146685075],\n",
       " [0.041211325711732534,\n",
       "  0.10395126122766728,\n",
       "  0.05143376920091783,\n",
       "  0.03007995417451672,\n",
       "  0.02474852286191344,\n",
       "  0.017573860924438137,\n",
       "  0.14524206682022806,\n",
       "  0.0,\n",
       "  0.16010138739836505,\n",
       "  0.14476867647333228,\n",
       "  0.07863493303125182,\n",
       "  0.03735784264043018,\n",
       "  0.04630379598874247,\n",
       "  0.02150403830375515,\n",
       "  0.024598761229627567,\n",
       "  0.03061152874205245,\n",
       "  0.03492674602033566,\n",
       "  0.01650230950305793,\n",
       "  0.13237621756045898,\n",
       "  0.12835696654011178,\n",
       "  0.03351703471733064,\n",
       "  0.034349768537800085,\n",
       "  0.05293382496192909,\n",
       "  0.06175851909284631,\n",
       "  0.0578870278010421,\n",
       "  0.04159904819816846],\n",
       " [0.04954798792149306,\n",
       "  0.15613583474175802,\n",
       "  0.15059978900014132,\n",
       "  0.040493671782387344,\n",
       "  0.039460845942010735,\n",
       "  0.037643236506740285,\n",
       "  0.17223378165843659,\n",
       "  0.04180847613816127,\n",
       "  0.11393671602074855,\n",
       "  0.15351575714979135,\n",
       "  0.2748704714578646,\n",
       "  0.14585142161119358,\n",
       "  0.131506193703634,\n",
       "  0.030815748072867043,\n",
       "  0.013276298447873687,\n",
       "  0.03488907542409306,\n",
       "  0.0372352896384569,\n",
       "  0.017196338903110092,\n",
       "  0.13905527907646525,\n",
       "  0.14564825448276317,\n",
       "  0.14590762276531338,\n",
       "  0.14414985358271745,\n",
       "  0.04614051304550691,\n",
       "  0.06594317363648115,\n",
       "  0.02853118878194282,\n",
       "  0.14760771847174423],\n",
       " [0.04270026772779714,\n",
       "  0.14554622749015161,\n",
       "  0.06085716049306006,\n",
       "  0.02955833792208458,\n",
       "  0.024641547952397876,\n",
       "  0.017433207433432737,\n",
       "  0.1006529827267193,\n",
       "  0.012980768010967453,\n",
       "  0.0,\n",
       "  0.04095045192528329,\n",
       "  0.08264825231474793,\n",
       "  0.022814874850765565,\n",
       "  0.03924856553852441,\n",
       "  0.02255134134801471,\n",
       "  0.02658528535598031,\n",
       "  0.028105572618126837,\n",
       "  0.026110620254441705,\n",
       "  0.018545566121421518,\n",
       "  0.1368346412660271,\n",
       "  0.043370740344727765,\n",
       "  0.02932352694329564,\n",
       "  0.025699781901704185,\n",
       "  0.054588185438587074,\n",
       "  0.15396703696380332,\n",
       "  0.06958299053605103,\n",
       "  0.021881835612640045],\n",
       " [0.04734229355411543,\n",
       "  0.1740698655448608,\n",
       "  0.17016861235814676,\n",
       "  0.03866724434581294,\n",
       "  0.04172168639354737,\n",
       "  0.03630441337656326,\n",
       "  0.0,\n",
       "  0.015620414122799277,\n",
       "  0.2057729255907925,\n",
       "  0.26319065713721346,\n",
       "  0.2635665951899785,\n",
       "  0.037525500125522804,\n",
       "  0.13257643904954464,\n",
       "  0.03067748516922235,\n",
       "  0.03040322159372202,\n",
       "  0.03550926771339834,\n",
       "  0.027186580130617935,\n",
       "  0.01924411403870447,\n",
       "  0.04148402250269053,\n",
       "  0.05121579886887778,\n",
       "  0.025429266223476438,\n",
       "  0.027399570562869846,\n",
       "  0.053729890154015275,\n",
       "  0.13575464378517293,\n",
       "  0.041497912861559516,\n",
       "  0.16726829173831861],\n",
       " [0.13345324887519455,\n",
       "  0.16183576167580768,\n",
       "  0.10296357225919942,\n",
       "  0.0797154066133501,\n",
       "  0.06897244245700124,\n",
       "  0.05635406322686837,\n",
       "  0.1435741074015598,\n",
       "  0.12948780364959622,\n",
       "  0.17024076301663055,\n",
       "  0.1092712107740649,\n",
       "  0.15055516408006014,\n",
       "  0.15958883272330063,\n",
       "  0.18282882864826708,\n",
       "  0.15930402991153877,\n",
       "  0.13366809024691273,\n",
       "  0.07899502410297589,\n",
       "  0.1399664223982469,\n",
       "  0.06869144851960625,\n",
       "  0.14411530497108668,\n",
       "  0.16181286835936928,\n",
       "  0.15970068742923996,\n",
       "  0.1595309143549876,\n",
       "  0.1369066151169437,\n",
       "  0.1494876417251138,\n",
       "  0.08442424801924923,\n",
       "  0.09206917577714956],\n",
       " [0.0,\n",
       "  0.19593226123455143,\n",
       "  0.26117234265166767,\n",
       "  0.05899042130646152,\n",
       "  0.077412819627114,\n",
       "  0.0477680438791139,\n",
       "  0.14495238937246008,\n",
       "  0.058205989595341415,\n",
       "  0.13874159549529913,\n",
       "  0.09386614055217939,\n",
       "  0.16012243680762822,\n",
       "  0.06462416241663238,\n",
       "  0.09284089457910172,\n",
       "  0.06816308148588639,\n",
       "  0.0540373481258523,\n",
       "  0.07264855680514525,\n",
       "  0.136064398905372,\n",
       "  0.052418054775026625,\n",
       "  0.0981283852963793,\n",
       "  0.0884373228430835,\n",
       "  0.05529939085016291,\n",
       "  0.05094157665659978,\n",
       "  0.2572923915486154,\n",
       "  0.09830216713547595,\n",
       "  0.056127294248781406,\n",
       "  0.15208645502944582],\n",
       " [0.14423982633821156,\n",
       "  0.1902074211884853,\n",
       "  0.1556507172087686,\n",
       "  0.14617167437302064,\n",
       "  0.13300722462690232,\n",
       "  0.04084257074606842,\n",
       "  0.17712922032043604,\n",
       "  0.0359838681377546,\n",
       "  0.26005373700778894,\n",
       "  0.17569282929086594,\n",
       "  0.15271632049857958,\n",
       "  0.03493703991376279,\n",
       "  0.12955992902337418,\n",
       "  0.02469713965251319,\n",
       "  0.01899338376544526,\n",
       "  0.02421986147808487,\n",
       "  0.04035262273553712,\n",
       "  0.021282861680658575,\n",
       "  0.15209864226450875,\n",
       "  0.13688806858169725,\n",
       "  0.03861490036232686,\n",
       "  0.036699953150708474,\n",
       "  0.050178163192291125,\n",
       "  0.1302168907634227,\n",
       "  0.038446875836705835,\n",
       "  0.04592340705589285],\n",
       " [0.13605642787495953,\n",
       "  0.1211017270647836,\n",
       "  0.05622992621859497,\n",
       "  0.03077676502255407,\n",
       "  0.029042440415190156,\n",
       "  0.018506410296221056,\n",
       "  0.16243184429827134,\n",
       "  0.016783589409651356,\n",
       "  0.27551288233937443,\n",
       "  0.05862067761576375,\n",
       "  0.17382706223704622,\n",
       "  0.027817963253436842,\n",
       "  0.04445069367046855,\n",
       "  0.028150312845775474,\n",
       "  0.02661656896859127,\n",
       "  0.032706778695574576,\n",
       "  0.02930812795913426,\n",
       "  0.020495118444236522,\n",
       "  0.056965686115359286,\n",
       "  0.042720472643688265,\n",
       "  0.03398452834655166,\n",
       "  0.03576693231204119,\n",
       "  0.057768910851714456,\n",
       "  0.07634386377049247,\n",
       "  0.027524047855105746,\n",
       "  0.1302935457075604],\n",
       " [0.04253292920438107,\n",
       "  0.0991586693222674,\n",
       "  0.0606813637444767,\n",
       "  0.02672865113612838,\n",
       "  0.020841507566955894,\n",
       "  0.010364632062031845,\n",
       "  0.17263542811426238,\n",
       "  0.0112717298478221,\n",
       "  0.09735503379109356,\n",
       "  0.25768288374008685,\n",
       "  0.27027147223145653,\n",
       "  0.024699190346038784,\n",
       "  0.034138988810330916,\n",
       "  0.019354052911189214,\n",
       "  0.024187272908950112,\n",
       "  0.028782645730945626,\n",
       "  0.01956988574193823,\n",
       "  0.015246641003621577,\n",
       "  0.034538552394632556,\n",
       "  0.036372694723384745,\n",
       "  0.02345606017079291,\n",
       "  0.022653173342755066,\n",
       "  0.04991467617809504,\n",
       "  0.061967884451478245,\n",
       "  0.017979319618161935,\n",
       "  0.02839083876020608],\n",
       " [0.1347644170512377,\n",
       "  0.14957934207670068,\n",
       "  0.05366611708654064,\n",
       "  0.05711408029996784,\n",
       "  0.14607727970003628,\n",
       "  0.14795866150638448,\n",
       "  0.14985188862336313,\n",
       "  0.0403020477969462,\n",
       "  0.15305749836037283,\n",
       "  0.14905291177057323,\n",
       "  0.1494992249610469,\n",
       "  0.047289620358206066,\n",
       "  0.15446313108741358,\n",
       "  0.1447550292156252,\n",
       "  0.04148285903414182,\n",
       "  0.14476834060530985,\n",
       "  0.1477341525912261,\n",
       "  0.2535444055644127,\n",
       "  0.2688638401631499,\n",
       "  0.14867293750659932,\n",
       "  0.04079777819791019,\n",
       "  0.12864934732475009,\n",
       "  0.14388801251899724,\n",
       "  0.06782542220470596,\n",
       "  0.03289236525033566,\n",
       "  0.14465484334622575],\n",
       " [0.02494022839750621,\n",
       "  0.12251956163532988,\n",
       "  0.05695197723440085,\n",
       "  0.024864454749617057,\n",
       "  0.02503414113904139,\n",
       "  0.017567773343729866,\n",
       "  0.16244536401522297,\n",
       "  0.013239153826918284,\n",
       "  0.10370404323717416,\n",
       "  0.07199175507331211,\n",
       "  0.27050626345129125,\n",
       "  0.1408509993586984,\n",
       "  0.14456983179287675,\n",
       "  0.023228129313630767,\n",
       "  0.027823343303602692,\n",
       "  0.03339935722388409,\n",
       "  0.017515342608438393,\n",
       "  0.018226551803688425,\n",
       "  0.04547717911062973,\n",
       "  0.038393162778011816,\n",
       "  0.02682248818395626,\n",
       "  0.0262544322742108,\n",
       "  0.05436794325014147,\n",
       "  0.13380816994932487,\n",
       "  0.049132601026566886,\n",
       "  0.023060593921015286],\n",
       " [0.14576170470465177,\n",
       "  0.2170868046168664,\n",
       "  0.14205802093599398,\n",
       "  0.27612746343115135,\n",
       "  0.2759409333125972,\n",
       "  0.1744896501540336,\n",
       "  0.18557893454865085,\n",
       "  0.137261703190552,\n",
       "  0.19194369867935432,\n",
       "  0.17159565855538686,\n",
       "  0.16304899350893648,\n",
       "  0.14739272364419204,\n",
       "  0.14135747962946804,\n",
       "  0.09713088471396791,\n",
       "  0.09530587318093264,\n",
       "  0.10373169740150338,\n",
       "  0.14509879013613866,\n",
       "  0.09259825459366691,\n",
       "  0.16667695001233118,\n",
       "  0.12051072457862885,\n",
       "  0.15849649236890886,\n",
       "  0.14574617580925303,\n",
       "  0.16421854919153642,\n",
       "  0.16282945515668962,\n",
       "  0.08921711404562925,\n",
       "  0.1632130275964748],\n",
       " [0.13221680679400438,\n",
       "  0.17960728210708532,\n",
       "  0.1840155221508749,\n",
       "  0.051062647415718435,\n",
       "  0.04802028553514594,\n",
       "  0.03596904850267731,\n",
       "  0.16127220284561922,\n",
       "  0.014265820186969043,\n",
       "  0.1891070652101368,\n",
       "  0.07169018149122547,\n",
       "  0.17330863679464267,\n",
       "  0.03143759363722828,\n",
       "  0.04423191970211228,\n",
       "  0.026716711160038254,\n",
       "  0.026708465140219857,\n",
       "  0.037186722438154574,\n",
       "  0.029057175964553178,\n",
       "  0.014924303336534403,\n",
       "  0.04823843488499462,\n",
       "  0.03915774659768248,\n",
       "  0.026155954791339822,\n",
       "  0.0338984354981912,\n",
       "  0.05723457682150031,\n",
       "  0.07575801367590115,\n",
       "  0.1510521900854918,\n",
       "  0.16021299179794699],\n",
       " [0.0,\n",
       "  0.27937543337969917,\n",
       "  0.26516793931736427,\n",
       "  0.13877401048175061,\n",
       "  0.1371060518634827,\n",
       "  0.04287344267465858,\n",
       "  0.15618713996739408,\n",
       "  0.02996332149492749,\n",
       "  0.14994970416655656,\n",
       "  0.06370309153793847,\n",
       "  0.13931731181509105,\n",
       "  0.046366071487029994,\n",
       "  0.1333272567881885,\n",
       "  0.03900165242231915,\n",
       "  0.03492950537921351,\n",
       "  0.0,\n",
       "  0.039201357023884525,\n",
       "  0.026353716813117045,\n",
       "  0.13121327965768523,\n",
       "  0.06579972739021568,\n",
       "  0.04683539090849531,\n",
       "  0.045512512660655535,\n",
       "  0.12953613498575917,\n",
       "  0.2729176096590374,\n",
       "  0.10858933503328122,\n",
       "  0.14385806145102342],\n",
       " [0.050824405228774475,\n",
       "  0.15236910202021595,\n",
       "  0.278081029437784,\n",
       "  0.04514160010927078,\n",
       "  0.051742978491769426,\n",
       "  0.049502543866401225,\n",
       "  0.13044614315851383,\n",
       "  0.01898348560283972,\n",
       "  0.14789096788108066,\n",
       "  0.0746937381268461,\n",
       "  0.1491799692695141,\n",
       "  0.04367029025149152,\n",
       "  0.1541723751641569,\n",
       "  0.04903477971881663,\n",
       "  0.05646646661537834,\n",
       "  0.05445359219653903,\n",
       "  0.13482902599259206,\n",
       "  0.04345285505571768,\n",
       "  0.07577075102458755,\n",
       "  0.06358207960035586,\n",
       "  0.050025374645350854,\n",
       "  0.05431993539447458,\n",
       "  0.13428214002177458,\n",
       "  0.1511805413481883,\n",
       "  0.04921378995698503,\n",
       "  0.1498560979969273]]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "83f247ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05478497, 0.13778558, 0.08850578, ..., 0.1888507 , 0.06009689,\n",
       "        0.09897783],\n",
       "       [0.1074768 , 0.        , 0.16539059, ..., 0.12171418, 0.07565459,\n",
       "        0.11266105],\n",
       "       [0.03244967, 0.19414264, 0.19156379, ..., 0.1052305 , 0.05821982,\n",
       "        0.08265515],\n",
       "       ...,\n",
       "       [0.07131466, 0.1613405 , 0.14152397, ..., 0.07575801, 0.07651286,\n",
       "        0.10057822],\n",
       "       [0.        , 0.20259935, 0.16887966, ..., 0.17136177, 0.09325372,\n",
       "        0.07075188],\n",
       "       [0.05526532, 0.13457735, 0.18009238, ..., 0.10431263, 0.04921379,\n",
       "        0.09553026]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf533e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#直接计算AUC值\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_true_m,y_pre_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900321ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#另一种计算AUC值的方法\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_true_m,y_pre_m)\n",
    "metrics.auc(fpr, tpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dd844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score, auc\n",
    "average_precision_score(y_true_m,y_pre_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f9a589",
   "metadata": {},
   "source": [
    "# setting2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ed05135",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 435.67it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "\n",
    "fold = 10\n",
    "dr_pre=np.loadtxt(\"./source_data/nr4_admat_dgc.txt\").T\n",
    "simdr=np.loadtxt(\"./source_data/nr_simmat_drug.txt\")\n",
    "simpre=np.loadtxt(\"./source_data/nr_simmat_target.txt\")\n",
    "\n",
    "prenum = len(simpre)\n",
    "drnum = len(simdr)\n",
    "\n",
    "# 获取药物的索引（矩阵的行索引）\n",
    "drug_indices = list(range(dr_pre.shape[0]))\n",
    "num_d = len(drug_indices)\n",
    "\n",
    "group_size1_d = int(num_d / fold)\n",
    "random.seed(10)\n",
    "random.shuffle(drug_indices)\n",
    "\n",
    "array_1=np.array(drug_indices)[0:fold*group_size1_d]\n",
    "group_data1=np.reshape(array_1,(fold,group_size1_d))\n",
    "\n",
    "f = 0\n",
    "for f in trange(fold):\n",
    "    DTI = np.copy(dr_pre)\n",
    "    i=0\n",
    "    while i < group_size1_d:\n",
    "        r = group_data1[f,i ] \n",
    "        c = np.where(DTI[group_data1[f, i], :] == 1)[0]\n",
    "        DTI[r, c] = 0\n",
    "        i += 1  # 得到每次交叉验证中所使用的A矩阵\n",
    "    np.savetxt(\"./dataset/DTI_setting2\"+str(f)+\".txt\",DTI)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dba74537",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 293.63it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 312.48it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 332.63it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 357.01it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 312.49it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 294.16it/s]\u001b[A\n",
      " 30%|████████████████████████▉                                                          | 3/10 [00:00<00:00, 21.99it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 333.34it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 301.92it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 270.35it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 277.78it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 277.72it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 312.58it/s]\u001b[A\n",
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [00:00<00:00, 22.02it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 312.26it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 277.71it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 312.49it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 277.80it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 312.23it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 285.64it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [00:00<00:00, 22.11it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 312.56it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 277.78it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 22.05it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 13508.23it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 18001.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8\n",
      "5 <class 'list'>\n",
      "<class 'numpy.ndarray'> 26\n",
      "The auc of prediction is: 0.988495652173913\n",
      "The aupr of prediction is: 0.9239999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 8997.08it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 18001.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.2\n",
      "5 <class 'list'>\n",
      "<class 'numpy.ndarray'> 26\n",
      "The auc of prediction is: 0.9797219172400332\n",
      "The aupr of prediction is: 0.921060295414462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 8986.01it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 18001.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n",
      "5 <class 'list'>\n",
      "<class 'numpy.ndarray'> 26\n",
      "The auc of prediction is: 0.9866666666666667\n",
      "The aupr of prediction is: 0.9164444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 8300.68it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 13498.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.8\n",
      "5 <class 'list'>\n",
      "<class 'numpy.ndarray'> 26\n",
      "The auc of prediction is: 0.9784822134387351\n",
      "The aupr of prediction is: 0.9405430495430496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 13500.98it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 13503.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2\n",
      "5 <class 'list'>\n",
      "<class 'numpy.ndarray'> 26\n",
      "The auc of prediction is: 0.9728868646943747\n",
      "The aupr of prediction is: 0.8861153745244654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 10798.21it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 10793.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8\n",
      "5 <class 'list'>\n",
      "<class 'numpy.ndarray'> 26\n",
      "The auc of prediction is: 0.9835965493443755\n",
      "The aupr of prediction is: 0.8978412698412699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 8999.22it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 17997.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.4\n",
      "5 <class 'list'>\n",
      "<class 'numpy.ndarray'> 26\n",
      "The auc of prediction is: 0.9694822796120737\n",
      "The aupr of prediction is: 0.8556947845804989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 10796.15it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 17998.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4\n",
      "5 <class 'list'>\n",
      "<class 'numpy.ndarray'> 26\n",
      "The auc of prediction is: 0.9938937198067633\n",
      "The aupr of prediction is: 0.9461111111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 13497.76it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 17985.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4\n",
      "5 <class 'list'>\n",
      "<class 'numpy.ndarray'> 26\n",
      "The auc of prediction is: 0.9955666666666666\n",
      "The aupr of prediction is: 0.955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 10809.55it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 17997.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.4\n",
      "5 <class 'list'>\n",
      "<class 'numpy.ndarray'> 26\n",
      "The auc of prediction is: 0.42417133195307105\n",
      "The aupr of prediction is: 0.09290161574240859\n",
      "The auc of prediction is: 0.9241507366752485\n",
      "The aupr of prediction is: 0.7569270316465825\n",
      "Runtime: 0.6035263538360596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %load run_main.py\n",
    "import numpy as np\n",
    "from function import *\n",
    "from tqdm import trange\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import sklearn.metrics\n",
    "import copy\n",
    "import time\n",
    "rs = 0.6\n",
    "n_fold=10\n",
    "eta=0.7\n",
    "l_1=5\n",
    "l_2=5\n",
    "fr=500\n",
    "fp=300\n",
    "K=20\n",
    "dr_pre=np.loadtxt(\"./source_data/nr4_admat_dgc.txt\").T\n",
    "simdr=np.loadtxt(\"./source_data/nr_simmat_drug.txt\")\n",
    "simpre=np.loadtxt(\"./source_data/nr_simmat_target.txt\")\n",
    "\n",
    "drnum=len(simdr)     #药物的数目\n",
    "#disnum=len(dr_dis[0])     #副作用的数目\n",
    "prenum=len(simpre)     #蛋白质的数目\n",
    "\n",
    "\n",
    "#index_1 = np.loadtxt(\"./dataset/index_1.txt\")\n",
    "#index_0 = np.loadtxt(\"./dataset/index_0.txt\")\n",
    "#index = np.hstack((index_1, index_0))     #水平拼接\n",
    "reala=dr_pre\n",
    "sr = simdr\n",
    "sd = simpre/100\n",
    "\n",
    "RR=np.zeros(dr_pre.shape)       #原始的邻接矩阵\n",
    "#A = np.hstack((dr_dr, dr_dis, dr_se))       #Fr\n",
    "#B = np.hstack((pre_pre, pre_dis))         #Fp\n",
    "#cutdr_dis = SVD(A, fr)    #奇异值分解    Fr'\n",
    "#cutpre_dis = SVD(B, fp)     #奇异值分解    Fp'\n",
    "#pre_simdti = cosine_similarity(cutpre_dis, cutpre_dis)    #计算余弦相似度   SrF\n",
    "#dr_simdti = cosine_similarity(cutdr_dis, cutdr_dis)        #计算余弦相似度   SpF\n",
    "pre_simdti = np.loadtxt(\"./source_data/S_FGS_p_nr.txt\")\n",
    "dr_simdti = np.loadtxt(\"./source_data/S_FGS_d_nr.txt\")\n",
    "\n",
    "# 获取药物的索引（矩阵的行索引）\n",
    "drug_indices = list(range(dr_pre.shape[0]))\n",
    "num_d = len(drug_indices)\n",
    "\n",
    "group_size1_d = int(num_d / fold)\n",
    "random.seed(10)\n",
    "random.shuffle(drug_indices)\n",
    "\n",
    "array_1=np.array(drug_indices)[0:fold*group_size1_d]\n",
    "group_data1=np.reshape(array_1,(fold,group_size1_d))\n",
    "# 获取靶点的索引（矩阵的列索引）\n",
    "protein_indices = list(range(dr_pre.shape[1]))\n",
    "\n",
    "# 记录开始时间\n",
    "start_time = time.time()\n",
    "\n",
    "srfp, spfp = pruning(K=K, drug_mat=dr_simdti, target_mat=pre_simdti, miu=eta)\n",
    "srsp, spsp = pruning(K=K, drug_mat=sr, target_mat=sd, miu=eta)\n",
    "\n",
    "for f in trange(n_fold):\n",
    "    a = np.loadtxt(\"./dataset/DTI\" + str(f) + \".txt\")\n",
    "    #idx=index[f,:]\n",
    "   \n",
    "    R = copy.deepcopy(a)\n",
    "    R = BiRW(R, dr_simdti, pre_simdti, a, rs)        \n",
    "    for i in trange(l_1):\n",
    "        R=BiRW(R, srfp, spfp, a, rs/2)\n",
    "    for i in trange(l_2):\n",
    "        R=BiRW(R, srsp, spsp, a, rs/2)\n",
    "\n",
    "    realvalue=np.zeros(R.shape)\n",
    "    for i in range(len(group_data1[f, :])): \n",
    "        d=group_data1[f, i]\n",
    "        p=np.where(DTI[group_data1[f, i], :] == 1)[0]\n",
    "        realvalue[d,p]=reala[d,p]\n",
    "    for i in range(len(group_data1[f, :])): \n",
    "        d=group_data1[f, i]\n",
    "        p=np.where(DTI[group_data1[f, i], :] == 1)[0]\n",
    "        RR[d,p]=R[d,p]\n",
    "\n",
    "y_true_m = dr_pre.tolist()\n",
    "y_pre_m = RR.tolist()\n",
    "\n",
    "tpr_cov=[[] for i in range(n_fold)]\n",
    "fpr_cov=[[] for i in range(n_fold)]\n",
    "recall_cov=[[] for i in range(n_fold)]\n",
    "precision_cov=[[] for i in range(n_fold)]\n",
    "\n",
    "for f in range(n_fold):\n",
    "    #idx=index[f,:]\n",
    "    singal=[[] for i in range(len(y_true_m))]\n",
    "    singal_test=[[] for i in range(len(y_true_m))]\n",
    "    for i in trange(len(y_true_m)):\n",
    "        for j in range(len(y_true_m[0])):\n",
    "            if i in group_data1[f, :] and j in protein_indices :\n",
    "                singal[i].append(y_true_m[i][j])\n",
    "                singal_test[i].append(y_pre_m[i][j])\n",
    "    y_true=singal\n",
    "    y_pre=singal_test\n",
    "\n",
    "    idx = []\n",
    "    tpr_list = []\n",
    "    fpr_list = []\n",
    "    recall_list = []\n",
    "    precision_list = []\n",
    "    c = 0\n",
    "    for i in trange(len(y_true)):\n",
    "        if np.sum(np.array(y_true[i])) == 0:\n",
    "            c += 1\n",
    "            continue\n",
    "        else:\n",
    "            tpr1, fpr1, precision1, recall1 = tpr_fpr_precision_recall(np.array(y_true[i]), np.array(y_pre[i]))\n",
    "            fpr_list.append(fpr1)\n",
    "            tpr_list.append(tpr1)\n",
    "            precision_list.append(precision1)\n",
    "            recall_list.append(recall1)\n",
    "    coverage = []\n",
    "\n",
    "    for i in tpr_list:\n",
    "        try:\n",
    "            coverage.append(i.index(1.0)+1)\n",
    "        except:\n",
    "            print('1')\n",
    "    print(np.mean(np.array(coverage)))\n",
    "\n",
    "    tpr = equal_len_list(tpr_list)\n",
    "    print(len(tpr ),type(tpr))\n",
    "    fpr = equal_len_list(fpr_list)\n",
    "    precision = equal_len_list(precision_list)\n",
    "    recall = equal_len_list(recall_list)\n",
    "    tpr_mean = np.mean(tpr, axis=0)\n",
    "    tpr_cov[f]=tpr_mean\n",
    "    print(type(tpr_mean),len(tpr_mean))\n",
    "    fpr_mean = np.mean(fpr, axis=0)\n",
    "    fpr_cov[f]=fpr_mean\n",
    "    recall_mean = np.mean(recall, axis=0)\n",
    "    recall_cov[f]=recall_mean\n",
    "    precision_mean = np.mean(precision, axis=0)\n",
    "    precision_cov[f]=precision_mean\n",
    "    print('The auc of prediction is:', sklearn.metrics.auc(fpr_mean, tpr_mean))\n",
    "    print('The aupr of prediction is:', sklearn.metrics.auc(recall_mean, precision_mean)+recall_mean[0]*precision_mean[0])\n",
    "\n",
    "tpr = equal_len_list(tpr_cov)\n",
    "fpr = equal_len_list(fpr_cov)\n",
    "precision = equal_len_list(precision_cov)\n",
    "recall = equal_len_list(recall_cov)\n",
    "\n",
    "tpr_mean_snf = np.mean(tpr, axis=0)\n",
    "fpr_mean_snf = np.mean(fpr, axis=0)\n",
    "recall_mean_snf = np.mean(recall, axis=0)\n",
    "precision_mean_snf = np.mean(precision, axis=0)\n",
    "\n",
    "# 记录结束时间并计算运行时间\n",
    "end_time = time.time()\n",
    "runtime = end_time - start_time\n",
    "\n",
    "print('The auc of prediction is:', sklearn.metrics.auc(fpr_mean_snf, tpr_mean_snf))\n",
    "print('The aupr of prediction is:', sklearn.metrics.auc(recall_mean_snf, precision_mean_snf)+recall_mean_snf[0]*precision_mean_snf[0])\n",
    "# 打印灵敏度和运行时间\n",
    "\n",
    "print('Runtime:', runtime)\n",
    "#np.savetxt('./result/fpr_list_snf.txt', fpr_mean_snf)\n",
    "#np.savetxt('./result/tpr_list.txt_snf', tpr_mean_snf)\n",
    "#np.savetxt('./result/recall_list.txt_snf', recall_mean_snf)\n",
    "#np.savetxt('./result/precision_list.txt_snf', precision_mean_snf)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ebfb1c",
   "metadata": {},
   "source": [
    "# setting3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "818e8972",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 626.09it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "\n",
    "fold = 10\n",
    "dr_pre=np.loadtxt(\"./source_data/nr4_admat_dgc.txt\").T\n",
    "simdr=np.loadtxt(\"./source_data/nr_simmat_drug.txt\")\n",
    "simpre=np.loadtxt(\"./source_data/nr_simmat_target.txt\")\n",
    "\n",
    "prenum = len(simpre)\n",
    "drnum = len(simdr)\n",
    "\n",
    "# 获取药物的索引（矩阵的行索引）\n",
    "drug_indices = list(range(dr_pre.shape[0]))\n",
    "num_d = len(drug_indices)\n",
    "group_size1_d = int(num_d / fold)\n",
    "random.seed(10)\n",
    "random.shuffle(drug_indices)\n",
    "\n",
    "# 获取靶点的索引（矩阵的列索引）\n",
    "protein_indices = list(range(dr_pre.shape[1]))\n",
    "num_p = len(protein_indices)\n",
    "group_size1_p = int(num_p / fold)\n",
    "random.seed(10)\n",
    "random.shuffle(protein_indices)\n",
    "\n",
    "array_1_p=np.array(protein_indices)[0:fold*group_size1_p]\n",
    "group_data1_p=np.reshape(array_1_p,(fold,group_size1_p))\n",
    "\n",
    "f = 0\n",
    "for f in trange(fold):\n",
    "    DTI = np.copy(dr_pre)\n",
    "    i=0\n",
    "    while i < group_size1_p:\n",
    "        r = np.where(dr_pre[:, group_data1_p[f, i]] == 1)[0]\n",
    "        c = group_data1_p[f, i]\n",
    "        DTI[r, c] = 0\n",
    "        i += 1  # 得到每次交叉验证中所使用的A矩阵\n",
    "    np.savetxt(\"./dataset/DTI_setting3\"+str(f)+\".txt\",DTI)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37c4c2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 294.10it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 311.85it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 357.13it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 321.58it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 294.12it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 294.13it/s]\u001b[A\n",
      " 30%|████████████████████████▉                                                          | 3/10 [00:00<00:00, 23.16it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 333.21it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 312.30it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 333.36it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 312.46it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 238.04it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 277.76it/s]\u001b[A\n",
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [00:00<00:00, 22.98it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 322.14it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 312.36it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 312.50it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 294.10it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 293.76it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 285.63it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [00:00<00:00, 23.19it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 277.79it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 294.09it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 22.95it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 13497.76it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 53978.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1666666666666667\n",
      "12 <class 'list'>\n",
      "<class 'numpy.ndarray'> 2\n",
      "The auc of prediction is: nan\n",
      "The aupr of prediction is: 0.9826388888888888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 8999.58it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 54184.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.25\n",
      "20 <class 'list'>\n",
      "<class 'numpy.ndarray'> 2\n",
      "The auc of prediction is: nan\n",
      "The aupr of prediction is: 0.9765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 8999.58it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 53991.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0625\n",
      "16 <class 'list'>\n",
      "<class 'numpy.ndarray'> 2\n",
      "The auc of prediction is: nan\n",
      "The aupr of prediction is: 0.99267578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 10795.63it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 26931.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "13 <class 'list'>\n",
      "<class 'numpy.ndarray'> 2\n",
      "The auc of prediction is: 1.0\n",
      "The aupr of prediction is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 7715.11it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 26992.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "8 <class 'list'>\n",
      "<class 'numpy.ndarray'> 2\n",
      "The auc of prediction is: 1.0\n",
      "The aupr of prediction is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 10799.75it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "5 <class 'list'>\n",
      "<class 'numpy.ndarray'> 2\n",
      "The auc of prediction is: 1.0\n",
      "The aupr of prediction is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 10796.66it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 54055.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "4 <class 'list'>\n",
      "<class 'numpy.ndarray'> 2\n",
      "The auc of prediction is: 1.0\n",
      "The aupr of prediction is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 8999.94it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 53978.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "6 <class 'list'>\n",
      "<class 'numpy.ndarray'> 2\n",
      "The auc of prediction is: 1.0\n",
      "The aupr of prediction is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 13495.35it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 27092.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "29 <class 'list'>\n",
      "<class 'numpy.ndarray'> 2\n",
      "The auc of prediction is: 1.0\n",
      "The aupr of prediction is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 13500.17it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 54016.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "22 <class 'list'>\n",
      "<class 'numpy.ndarray'> 2\n",
      "The auc of prediction is: 1.0\n",
      "The aupr of prediction is: 1.0\n",
      "The auc of prediction is: nan\n",
      "The aupr of prediction is: 0.9942974175347222\n",
      "Runtime: 0.5543041229248047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %load run_main.py\n",
    "import numpy as np\n",
    "from function import *\n",
    "from tqdm import trange\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import sklearn.metrics\n",
    "import copy\n",
    "import time\n",
    "rs = 0.6\n",
    "n_fold=10\n",
    "eta=0.7\n",
    "l_1=5\n",
    "l_2=5\n",
    "fr=500\n",
    "fp=300\n",
    "K=20\n",
    "dr_pre=np.loadtxt(\"./source_data/nr4_admat_dgc.txt\").T\n",
    "simdr=np.loadtxt(\"./source_data/nr_simmat_drug.txt\")\n",
    "simpre=np.loadtxt(\"./source_data/nr_simmat_target.txt\")\n",
    "\n",
    "drnum=len(simdr)     #药物的数目\n",
    "#disnum=len(dr_dis[0])     #副作用的数目\n",
    "prenum=len(simpre)     #蛋白质的数目\n",
    "\n",
    "\n",
    "#index_1 = np.loadtxt(\"./dataset/index_1.txt\")\n",
    "#index_0 = np.loadtxt(\"./dataset/index_0.txt\")\n",
    "#index = np.hstack((index_1, index_0))     #水平拼接\n",
    "reala=dr_pre\n",
    "sr = simdr\n",
    "sd = simpre/100\n",
    "\n",
    "RR=np.zeros(dr_pre.shape)       #原始的邻接矩阵\n",
    "#A = np.hstack((dr_dr, dr_dis, dr_se))       #Fr\n",
    "#B = np.hstack((pre_pre, pre_dis))         #Fp\n",
    "#cutdr_dis = SVD(A, fr)    #奇异值分解    Fr'\n",
    "#cutpre_dis = SVD(B, fp)     #奇异值分解    Fp'\n",
    "#pre_simdti = cosine_similarity(cutpre_dis, cutpre_dis)    #计算余弦相似度   SrF\n",
    "#dr_simdti = cosine_similarity(cutdr_dis, cutdr_dis)        #计算余弦相似度   SpF\n",
    "pre_simdti = np.loadtxt(\"./source_data/S_FGS_p_nr.txt\")\n",
    "dr_simdti = np.loadtxt(\"./source_data/S_FGS_d_nr.txt\")\n",
    "\n",
    "# 获取靶点的索引（矩阵的列索引）\n",
    "protein_indices = list(range(dr_pre.shape[1]))\n",
    "num_p = len(protein_indices)\n",
    "group_size1_p = int(num_p / fold)\n",
    "random.seed(10)\n",
    "random.shuffle(protein_indices)\n",
    "\n",
    "array_1_p=np.array(protein_indices)[0:fold*group_size1_p]\n",
    "group_data1_p=np.reshape(array_1_p,(fold,group_size1_p))\n",
    "\n",
    "# 记录开始时间\n",
    "start_time = time.time()\n",
    "\n",
    "srfp, spfp = pruning(K=K, drug_mat=dr_simdti, target_mat=pre_simdti, miu=eta)\n",
    "srsp, spsp = pruning(K=K, drug_mat=sr, target_mat=sd, miu=eta)\n",
    "\n",
    "for f in trange(n_fold):\n",
    "    a = np.loadtxt(\"./dataset/DTI_setting3\" + str(f) + \".txt\")\n",
    "    #idx=index[f,:]\n",
    "   \n",
    "    R = copy.deepcopy(a)\n",
    "    R = BiRW(R, dr_simdti, pre_simdti, a, rs)        \n",
    "    for i in trange(l_1):\n",
    "        R=BiRW(R, srfp, spfp, a, rs/2)\n",
    "    for i in trange(l_2):\n",
    "        R=BiRW(R, srsp, spsp, a, rs/2)\n",
    "\n",
    "    realvalue=np.zeros(R.shape)\n",
    "    for i in range(len(group_data1_p[f, :])): \n",
    "        d=np.where(dr_pre[:, group_data1_p[f, i]] == 1)[0]\n",
    "        p=group_data1_p[f, i]\n",
    "        realvalue[d,p]=reala[d,p]\n",
    "    for i in range(len(group_data1_p[f, :])): \n",
    "        d=np.where(dr_pre[:, group_data1_p[f, i]] == 1)[0]\n",
    "        p=group_data1_p[f, i]\n",
    "        RR[d,p]=R[d,p]\n",
    "\n",
    "y_true_m = dr_pre.tolist()\n",
    "y_pre_m = RR.tolist()\n",
    "\n",
    "tpr_cov=[[] for i in range(n_fold)]\n",
    "fpr_cov=[[] for i in range(n_fold)]\n",
    "recall_cov=[[] for i in range(n_fold)]\n",
    "precision_cov=[[] for i in range(n_fold)]\n",
    "\n",
    "for f in range(n_fold):\n",
    "    #idx=index[f,:]\n",
    "    singal=[[] for i in range(len(y_true_m))]\n",
    "    singal_test=[[] for i in range(len(y_true_m))]\n",
    "    for i in trange(len(y_true_m)):\n",
    "        for j in range(len(y_true_m[0])):\n",
    "            if i in drug_indices and j in group_data1_p[f, :] :\n",
    "                singal[i].append(y_true_m[i][j])\n",
    "                singal_test[i].append(y_pre_m[i][j])\n",
    "    y_true=singal\n",
    "    y_pre=singal_test\n",
    "\n",
    "    idx = []\n",
    "    tpr_list = []\n",
    "    fpr_list = []\n",
    "    recall_list = []\n",
    "    precision_list = []\n",
    "    c = 0\n",
    "    for i in trange(len(y_true)):\n",
    "        if np.sum(np.array(y_true[i])) == 0:\n",
    "            c += 1\n",
    "            continue\n",
    "        else:\n",
    "            tpr1, fpr1, precision1, recall1 = tpr_fpr_precision_recall(np.array(y_true[i]), np.array(y_pre[i]))\n",
    "            fpr_list.append(fpr1)\n",
    "            tpr_list.append(tpr1)\n",
    "            precision_list.append(precision1)\n",
    "            recall_list.append(recall1)\n",
    "    coverage = []\n",
    "\n",
    "    for i in tpr_list:\n",
    "        try:\n",
    "            coverage.append(i.index(1.0)+1)\n",
    "        except:\n",
    "            print('1')\n",
    "    print(np.mean(np.array(coverage)))\n",
    "\n",
    "    tpr = equal_len_list(tpr_list)\n",
    "    print(len(tpr ),type(tpr))\n",
    "    fpr = equal_len_list(fpr_list)\n",
    "    precision = equal_len_list(precision_list)\n",
    "    recall = equal_len_list(recall_list)\n",
    "    tpr_mean = np.mean(tpr, axis=0)\n",
    "    tpr_cov[f]=tpr_mean\n",
    "    print(type(tpr_mean),len(tpr_mean))\n",
    "    fpr_mean = np.mean(fpr, axis=0)\n",
    "    fpr_cov[f]=fpr_mean\n",
    "    recall_mean = np.mean(recall, axis=0)\n",
    "    recall_cov[f]=recall_mean\n",
    "    precision_mean = np.mean(precision, axis=0)\n",
    "    precision_cov[f]=precision_mean\n",
    "    print('The auc of prediction is:', sklearn.metrics.auc(fpr_mean, tpr_mean))\n",
    "    print('The aupr of prediction is:', sklearn.metrics.auc(recall_mean, precision_mean)+recall_mean[0]*precision_mean[0])\n",
    "\n",
    "tpr = equal_len_list(tpr_cov)\n",
    "fpr = equal_len_list(fpr_cov)\n",
    "precision = equal_len_list(precision_cov)\n",
    "recall = equal_len_list(recall_cov)\n",
    "\n",
    "tpr_mean_snf = np.mean(tpr, axis=0)\n",
    "fpr_mean_snf = np.mean(fpr, axis=0)\n",
    "recall_mean_snf = np.mean(recall, axis=0)\n",
    "precision_mean_snf = np.mean(precision, axis=0)\n",
    "\n",
    "# 记录结束时间并计算运行时间\n",
    "end_time = time.time()\n",
    "runtime = end_time - start_time\n",
    "\n",
    "print('The auc of prediction is:', sklearn.metrics.auc(fpr_mean_snf, tpr_mean_snf))\n",
    "print('The aupr of prediction is:', sklearn.metrics.auc(recall_mean_snf, precision_mean_snf)+recall_mean_snf[0]*precision_mean_snf[0])\n",
    "# 打印灵敏度和运行时间\n",
    "\n",
    "print('Runtime:', runtime)\n",
    "#np.savetxt('./result/fpr_list_snf.txt', fpr_mean_snf)\n",
    "#np.savetxt('./result/tpr_list.txt_snf', tpr_mean_snf)\n",
    "#np.savetxt('./result/recall_list.txt_snf', recall_mean_snf)\n",
    "#np.savetxt('./result/precision_list.txt_snf', precision_mean_snf)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678c5957",
   "metadata": {},
   "source": [
    "# setting4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b2c64cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 588.23it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "\n",
    "fold = 10\n",
    "dr_pre=np.loadtxt(\"./source_data/nr4_admat_dgc.txt\").T\n",
    "simdr=np.loadtxt(\"./source_data/nr_simmat_drug.txt\")\n",
    "simpre=np.loadtxt(\"./source_data/nr_simmat_target.txt\")\n",
    "\n",
    "prenum = len(simpre)\n",
    "drnum = len(simdr)\n",
    "\n",
    "# 获取药物的索引（矩阵的行索引）\n",
    "drug_indices = list(range(dr_pre.shape[0]))\n",
    "num_d = len(drug_indices)\n",
    "group_size1_d = int(num_d / fold)\n",
    "random.seed(10)\n",
    "random.shuffle(drug_indices)\n",
    "array_1=np.array(drug_indices)[0:fold*group_size1_d]\n",
    "group_data1=np.reshape(array_1,(fold,group_size1_d))\n",
    "\n",
    "# 获取靶点的索引（矩阵的列索引）\n",
    "protein_indices = list(range(dr_pre.shape[1]))\n",
    "num_p = len(protein_indices)\n",
    "group_size1_p = int(num_p / fold)\n",
    "random.seed(10)\n",
    "random.shuffle(protein_indices)\n",
    "\n",
    "array_1_p=np.array(protein_indices)[0:fold*group_size1_p]\n",
    "group_data1_p=np.reshape(array_1_p,(fold,group_size1_p))\n",
    "\n",
    "f = 0\n",
    "for f in trange(fold):\n",
    "    DTI = np.copy(dr_pre)\n",
    "    i=0\n",
    "    while i < group_size1_d:\n",
    "        r = group_data1[f,i ] \n",
    "        c = np.where(DTI[group_data1[f, i], :] == 1)[0]\n",
    "        DTI[r, c] = 0\n",
    "        i += 1  # 得到每次交叉验证中所使用的A矩阵\n",
    "\n",
    "    while i < group_size1_p:\n",
    "        r = np.where(dr_pre[:, group_data1_p[f, i]] == 1)[0]\n",
    "        c = group_data1_p[f, i]\n",
    "        DTI[r, c] = 0\n",
    "        i += 1  # 得到每次交叉验证中所使用的A矩阵\n",
    "    np.savetxt(\"./dataset/DTI_setting4\"+str(f)+\".txt\",DTI)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4f15304",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 333.35it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 270.16it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 277.79it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 263.17it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 357.10it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 333.28it/s]\u001b[A\n",
      " 30%|████████████████████████▉                                                          | 3/10 [00:00<00:00, 22.81it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 333.33it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 263.17it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 294.11it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 294.12it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 232.52it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 294.13it/s]\u001b[A\n",
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [00:00<00:00, 22.36it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 277.81it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 384.58it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 294.07it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 243.82it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 312.40it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 312.51it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [00:00<00:00, 22.33it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 357.15it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 302.86it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 22.55it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 7709.59it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 13480.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1875\n",
      "16 <class 'list'>\n",
      "<class 'numpy.ndarray'> 2\n",
      "The auc of prediction is: nan\n",
      "The aupr of prediction is: 0.6764729817708333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 7715.63it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 10801.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8260869565217392\n",
      "23 <class 'list'>\n",
      "<class 'numpy.ndarray'> 2\n",
      "The auc of prediction is: nan\n",
      "The aupr of prediction is: 0.6841636558673421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 5399.88it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 13502.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.142857142857143\n",
      "21 <class 'list'>\n",
      "<class 'numpy.ndarray'> 2\n",
      "The auc of prediction is: nan\n",
      "The aupr of prediction is: 0.9229024943310657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 5999.96it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 13499.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.133333333333333\n",
      "15 <class 'list'>\n",
      "<class 'numpy.ndarray'> 2\n",
      "The auc of prediction is: 0.5370390720390721\n",
      "The aupr of prediction is: 0.6466579452293737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 6748.28it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 13500.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0\n",
      "13 <class 'list'>\n",
      "<class 'numpy.ndarray'> 2\n",
      "The auc of prediction is: 0.7670333857464036\n",
      "The aupr of prediction is: 0.7661657253003407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 6338.82it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 13505.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.9\n",
      "10 <class 'list'>\n",
      "<class 'numpy.ndarray'> 2\n",
      "The auc of prediction is: 0.6905864197530864\n",
      "The aupr of prediction is: 0.6095238095238096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 6750.89it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 27011.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0\n",
      "9 <class 'list'>\n",
      "<class 'numpy.ndarray'> 2\n",
      "The auc of prediction is: 0.6673253206175016\n",
      "The aupr of prediction is: 0.6626963130931385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 6750.29it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 18002.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.363636363636363\n",
      "11 <class 'list'>\n",
      "<class 'numpy.ndarray'> 2\n",
      "The auc of prediction is: 0.790962264447113\n",
      "The aupr of prediction is: 0.643841007477371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 6747.07it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 13515.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9333333333333333\n",
      "30 <class 'list'>\n",
      "<class 'numpy.ndarray'> 2\n",
      "The auc of prediction is: 0.8427297008547009\n",
      "The aupr of prediction is: 0.8555059523809524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 5999.80it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 54/54 [00:00<00:00, 10799.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.884615384615385\n",
      "26 <class 'list'>\n",
      "<class 'numpy.ndarray'> 2\n",
      "The auc of prediction is: 0.843769449923296\n",
      "The aupr of prediction is: 0.7294484361792054\n",
      "The auc of prediction is: nan\n",
      "The aupr of prediction is: 0.7157748694896341\n",
      "Runtime: 0.6220710277557373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %load run_main.py\n",
    "import numpy as np\n",
    "from function import *\n",
    "from tqdm import trange\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import sklearn.metrics\n",
    "import copy\n",
    "import time\n",
    "rs = 0.6\n",
    "n_fold=10\n",
    "eta=0.7\n",
    "l_1=5\n",
    "l_2=5\n",
    "fr=500\n",
    "fp=300\n",
    "K=20\n",
    "dr_pre=np.loadtxt(\"./source_data/nr4_admat_dgc.txt\").T\n",
    "simdr=np.loadtxt(\"./source_data/nr_simmat_drug.txt\")\n",
    "simpre=np.loadtxt(\"./source_data/nr_simmat_target.txt\")\n",
    "\n",
    "drnum=len(simdr)     #药物的数目\n",
    "#disnum=len(dr_dis[0])     #副作用的数目\n",
    "prenum=len(simpre)     #蛋白质的数目\n",
    "\n",
    "\n",
    "#index_1 = np.loadtxt(\"./dataset/index_1.txt\")\n",
    "#index_0 = np.loadtxt(\"./dataset/index_0.txt\")\n",
    "#index = np.hstack((index_1, index_0))     #水平拼接\n",
    "reala=dr_pre\n",
    "sr = simdr\n",
    "sd = simpre/100\n",
    "\n",
    "RR=np.zeros(dr_pre.shape)       #原始的邻接矩阵\n",
    "RR_1=np.zeros(dr_pre.shape)       #原始的邻接矩阵\n",
    "#A = np.hstack((dr_dr, dr_dis, dr_se))       #Fr\n",
    "#B = np.hstack((pre_pre, pre_dis))         #Fp\n",
    "#cutdr_dis = SVD(A, fr)    #奇异值分解    Fr'\n",
    "#cutpre_dis = SVD(B, fp)     #奇异值分解    Fp'\n",
    "#pre_simdti = cosine_similarity(cutpre_dis, cutpre_dis)    #计算余弦相似度   SrF\n",
    "#dr_simdti = cosine_similarity(cutdr_dis, cutdr_dis)        #计算余弦相似度   SpF\n",
    "pre_simdti = np.loadtxt(\"./source_data/S_FGS_p_nr.txt\")\n",
    "dr_simdti = np.loadtxt(\"./source_data/S_FGS_d_nr.txt\")\n",
    "\n",
    "# 获取药物的索引（矩阵的行索引）\n",
    "drug_indices = list(range(dr_pre.shape[0]))\n",
    "num_d = len(drug_indices)\n",
    "group_size1_d = int(num_d / fold)\n",
    "random.seed(10)\n",
    "random.shuffle(drug_indices)\n",
    "array_1=np.array(drug_indices)[0:fold*group_size1_d]\n",
    "group_data1=np.reshape(array_1,(fold,group_size1_d))\n",
    "\n",
    "# 获取靶点的索引（矩阵的列索引）\n",
    "protein_indices = list(range(dr_pre.shape[1]))\n",
    "num_p = len(protein_indices)\n",
    "group_size1_p = int(num_p / fold)\n",
    "random.seed(10)\n",
    "random.shuffle(protein_indices)\n",
    "\n",
    "array_1_p=np.array(protein_indices)[0:fold*group_size1_p]\n",
    "group_data1_p=np.reshape(array_1_p,(fold,group_size1_p))\n",
    "\n",
    "# 记录开始时间\n",
    "start_time = time.time()\n",
    "\n",
    "srfp, spfp = pruning(K=K, drug_mat=dr_simdti, target_mat=pre_simdti, miu=eta)\n",
    "srsp, spsp = pruning(K=K, drug_mat=sr, target_mat=sd, miu=eta)\n",
    "\n",
    "for f in trange(n_fold):\n",
    "    a = np.loadtxt(\"./dataset/DTI_setting4\" + str(f) + \".txt\")\n",
    "    #idx=index[f,:]\n",
    "   \n",
    "    R = copy.deepcopy(a)\n",
    "    R = BiRW(R, dr_simdti, pre_simdti, a, rs)        \n",
    "    for i in trange(l_1):\n",
    "        R=BiRW(R, srfp, spfp, a, rs/2)\n",
    "    for i in trange(l_2):\n",
    "        R=BiRW(R, srsp, spsp, a, rs/2)\n",
    "\n",
    "    realvalue=np.zeros(R.shape)\n",
    "    realvalue_1=np.zeros(R.shape)\n",
    "    for i in range(len(group_data1[f, :])): \n",
    "        d=group_data1[f, i]\n",
    "        p=np.where(DTI[group_data1[f, i], :] == 1)[0]\n",
    "        realvalue_1[d,p]=reala[d,p]\n",
    "    for i in range(len(group_data1_p[f, :])): \n",
    "        d=np.where(dr_pre[:, group_data1_p[f, i]] == 1)[0]\n",
    "        p=group_data1_p[f, i]\n",
    "        realvalue[d,p]=realvalue_1[d,p]\n",
    "    for i in range(len(group_data1[f, :])): \n",
    "        d=group_data1[f, i]\n",
    "        p=np.where(DTI[group_data1[f, i], :] == 1)[0]\n",
    "        RR_1[d,p]=R[d,p]\n",
    "    for i in range(len(group_data1_p[f, :])): \n",
    "        d=np.where(dr_pre[:, group_data1_p[f, i]] == 1)[0]\n",
    "        p=group_data1_p[f, i]\n",
    "        RR[d,p]=RR_1[d,p]\n",
    "\n",
    "    \n",
    "y_true_m = dr_pre.tolist()\n",
    "y_pre_m = RR.tolist()\n",
    "\n",
    "tpr_cov=[[] for i in range(n_fold)]\n",
    "fpr_cov=[[] for i in range(n_fold)]\n",
    "recall_cov=[[] for i in range(n_fold)]\n",
    "precision_cov=[[] for i in range(n_fold)]\n",
    "\n",
    "for f in range(n_fold):\n",
    "    #idx=index[f,:]\n",
    "    singal=[[] for i in range(len(y_true_m))]\n",
    "    singal_test=[[] for i in range(len(y_true_m))]\n",
    "    for i in trange(len(y_true_m)):\n",
    "        for j in range(len(y_true_m[0])):\n",
    "            if i in drug_indices and j in group_data1_p[f, :] :\n",
    "                singal[i].append(y_true_m[i][j])\n",
    "                singal_test[i].append(y_pre_m[i][j])\n",
    "            if i in group_data1[f, :] and j in protein_indices :\n",
    "                singal[i].append(y_true_m[i][j])\n",
    "                singal_test[i].append(y_pre_m[i][j])\n",
    "    y_true=singal\n",
    "    y_pre=singal_test\n",
    "\n",
    "    idx = []\n",
    "    tpr_list = []\n",
    "    fpr_list = []\n",
    "    recall_list = []\n",
    "    precision_list = []\n",
    "    c = 0\n",
    "    for i in trange(len(y_true)):\n",
    "        if np.sum(np.array(y_true[i])) == 0:\n",
    "            c += 1\n",
    "            continue\n",
    "        else:\n",
    "            tpr1, fpr1, precision1, recall1 = tpr_fpr_precision_recall(np.array(y_true[i]), np.array(y_pre[i]))\n",
    "            fpr_list.append(fpr1)\n",
    "            tpr_list.append(tpr1)\n",
    "            precision_list.append(precision1)\n",
    "            recall_list.append(recall1)\n",
    "    coverage = []\n",
    "\n",
    "    for i in tpr_list:\n",
    "        try:\n",
    "            coverage.append(i.index(1.0)+1)\n",
    "        except:\n",
    "            print('1')\n",
    "    print(np.mean(np.array(coverage)))\n",
    "\n",
    "    tpr = equal_len_list(tpr_list)\n",
    "    print(len(tpr ),type(tpr))\n",
    "    fpr = equal_len_list(fpr_list)\n",
    "    precision = equal_len_list(precision_list)\n",
    "    recall = equal_len_list(recall_list)\n",
    "    tpr_mean = np.mean(tpr, axis=0)\n",
    "    tpr_cov[f]=tpr_mean\n",
    "    print(type(tpr_mean),len(tpr_mean))\n",
    "    fpr_mean = np.mean(fpr, axis=0)\n",
    "    fpr_cov[f]=fpr_mean\n",
    "    recall_mean = np.mean(recall, axis=0)\n",
    "    recall_cov[f]=recall_mean\n",
    "    precision_mean = np.mean(precision, axis=0)\n",
    "    precision_cov[f]=precision_mean\n",
    "    print('The auc of prediction is:', sklearn.metrics.auc(fpr_mean, tpr_mean))\n",
    "    print('The aupr of prediction is:', sklearn.metrics.auc(recall_mean, precision_mean)+recall_mean[0]*precision_mean[0])\n",
    "\n",
    "tpr = equal_len_list(tpr_cov)\n",
    "fpr = equal_len_list(fpr_cov)\n",
    "precision = equal_len_list(precision_cov)\n",
    "recall = equal_len_list(recall_cov)\n",
    "\n",
    "tpr_mean_snf = np.mean(tpr, axis=0)\n",
    "fpr_mean_snf = np.mean(fpr, axis=0)\n",
    "recall_mean_snf = np.mean(recall, axis=0)\n",
    "precision_mean_snf = np.mean(precision, axis=0)\n",
    "\n",
    "# 记录结束时间并计算运行时间\n",
    "end_time = time.time()\n",
    "runtime = end_time - start_time\n",
    "\n",
    "print('The auc of prediction is:', sklearn.metrics.auc(fpr_mean_snf, tpr_mean_snf))\n",
    "print('The aupr of prediction is:', sklearn.metrics.auc(recall_mean_snf, precision_mean_snf)+recall_mean_snf[0]*precision_mean_snf[0])\n",
    "# 打印灵敏度和运行时间\n",
    "\n",
    "print('Runtime:', runtime)\n",
    "#np.savetxt('./result/fpr_list_snf.txt', fpr_mean_snf)\n",
    "#np.savetxt('./result/tpr_list.txt_snf', tpr_mean_snf)\n",
    "#np.savetxt('./result/recall_list.txt_snf', recall_mean_snf)\n",
    "#np.savetxt('./result/precision_list.txt_snf', precision_mean_snf)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94d010f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
